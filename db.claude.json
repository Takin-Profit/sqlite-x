{
  "formatVersion": "1.0",
  "bundleType": "source-code",
  "bundledAt": "2025-01-25T16:50:28.370Z",
  "projectRoot": "src",
  "files": {
    "cache.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport type { StatementSync } from \"node:sqlite\"\n\ninterface CacheItem<V> {\n\tvalue: V\n\texpiry?: number\n}\n\nexport type Options<K, V> = {\n\treadonly maxAge?: number\n\treadonly maxSize: number\n\tonEviction?: (key: K, value: V) => void\n}\n\n// We'll create a base class that doesn't extend Map to avoid the iterator issues\nexport class LRUBase<K, V> {\n\t#size = 0\n\t#cache = new Map<K, CacheItem<V>>()\n\t#oldCache = new Map<K, CacheItem<V>>()\n\t#maxSize: number\n\t#maxAge: number\n\t#onEviction?: (key: K, value: V) => void\n\n\tconstructor(options: Options<K, V>) {\n\t\tif (!(options.maxSize && options.maxSize > 0)) {\n\t\t\tthrow new TypeError(\"`maxSize` must be a number greater than 0\")\n\t\t}\n\n\t\tif (typeof options.maxAge === \"number\" && options.maxAge === 0) {\n\t\t\tthrow new TypeError(\"`maxAge` must be a number greater than 0\")\n\t\t}\n\n\t\tthis.#maxSize = options.maxSize\n\t\tthis.#maxAge = options.maxAge || Number.POSITIVE_INFINITY\n\t\tthis.#onEviction = options.onEviction\n\t}\n\n\tprotected get cache(): Map<K, CacheItem<V>> {\n\t\treturn this.#cache\n\t}\n\n\tprotected get oldCache(): Map<K, CacheItem<V>> {\n\t\treturn this.#oldCache\n\t}\n\n\t#emitEvictions(cache: Map<K, CacheItem<V>>): void {\n\t\tif (typeof this.#onEviction !== \"function\") {\n\t\t\treturn\n\t\t}\n\n\t\tfor (const [key, item] of cache) {\n\t\t\tthis.#onEviction(key, item.value)\n\t\t}\n\t}\n\n\t#deleteIfExpired(key: K, item: CacheItem<V>): boolean {\n\t\tif (typeof item.expiry === \"number\" && item.expiry <= Date.now()) {\n\t\t\tif (typeof this.#onEviction === \"function\") {\n\t\t\t\tthis.#onEviction(key, item.value)\n\t\t\t}\n\n\t\t\treturn this.delete(key)\n\t\t}\n\n\t\treturn false\n\t}\n\n\t#getOrDeleteIfExpired(key: K, item: CacheItem<V>): V | undefined {\n\t\tconst deleted = this.#deleteIfExpired(key, item)\n\t\tif (deleted === false) {\n\t\t\treturn item.value\n\t\t}\n\t\treturn undefined\n\t}\n\n\t#getItemValue(key: K, item: CacheItem<V>): V | undefined {\n\t\treturn item.expiry ? this.#getOrDeleteIfExpired(key, item) : item.value\n\t}\n\n\t#peek(key: K, cache: Map<K, CacheItem<V>>): V | undefined {\n\t\tconst item = cache.get(key)\n\t\tif (!item) {\n\t\t\treturn undefined\n\t\t}\n\t\treturn this.#getItemValue(key, item)\n\t}\n\n\t#set(key: K, value: CacheItem<V>): void {\n\t\tthis.#cache.set(key, value)\n\t\tthis.#size++\n\n\t\tif (this.#size >= this.#maxSize) {\n\t\t\tthis.#size = 0\n\t\t\tthis.#emitEvictions(this.#oldCache)\n\t\t\tthis.#oldCache = this.#cache\n\t\t\tthis.#cache = new Map()\n\t\t}\n\t}\n\n\t#moveToRecent(key: K, item: CacheItem<V>): void {\n\t\tthis.#oldCache.delete(key)\n\t\tthis.#set(key, item)\n\t}\n\n\t*#entriesAscending(): IterableIterator<[K, CacheItem<V>]> {\n\t\tfor (const item of this.#oldCache) {\n\t\t\tconst [key, value] = item\n\t\t\tif (!this.#cache.has(key)) {\n\t\t\t\tconst deleted = this.#deleteIfExpired(key, value)\n\t\t\t\tif (deleted === false) {\n\t\t\t\t\tyield item\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (const item of this.#cache) {\n\t\t\tconst [key, value] = item\n\t\t\tconst deleted = this.#deleteIfExpired(key, value)\n\t\t\tif (deleted === false) {\n\t\t\t\tyield item\n\t\t\t}\n\t\t}\n\t}\n\n\tget(key: K): V | undefined {\n\t\tif (this.#cache.has(key)) {\n\t\t\tconst item = this.#cache.get(key)\n\t\t\tif (!item) {\n\t\t\t\treturn undefined\n\t\t\t}\n\t\t\treturn this.#getItemValue(key, item)\n\t\t}\n\n\t\tif (this.#oldCache.has(key)) {\n\t\t\tconst item = this.#oldCache.get(key)\n\t\t\tif (!item) {\n\t\t\t\treturn undefined\n\t\t\t}\n\t\t\tif (this.#deleteIfExpired(key, item) === false) {\n\t\t\t\tthis.#moveToRecent(key, item)\n\t\t\t\treturn item.value\n\t\t\t}\n\t\t}\n\t\treturn undefined\n\t}\n\n\tset(key: K, value: V, options: { maxAge?: number } = {}): this {\n\t\tconst maxAge = options.maxAge ?? this.#maxAge\n\n\t\tconst expiry =\n\t\t\ttypeof maxAge === \"number\" && maxAge !== Number.POSITIVE_INFINITY\n\t\t\t\t? Date.now() + maxAge\n\t\t\t\t: undefined\n\n\t\tif (this.#cache.has(key)) {\n\t\t\tthis.#cache.set(key, {\n\t\t\t\tvalue,\n\t\t\t\texpiry,\n\t\t\t})\n\t\t} else {\n\t\t\tthis.#set(key, { value, expiry })\n\t\t}\n\n\t\treturn this\n\t}\n\n\thas(key: K): boolean {\n\t\tif (this.#cache.has(key)) {\n\t\t\tconst item = this.#cache.get(key)\n\t\t\tif (!item) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn !this.#deleteIfExpired(key, item)\n\t\t}\n\n\t\tif (this.#oldCache.has(key)) {\n\t\t\tconst item = this.#oldCache.get(key)\n\t\t\tif (!item) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn !this.#deleteIfExpired(key, item)\n\t\t}\n\n\t\treturn false\n\t}\n\n\tpeek(key: K): V | undefined {\n\t\tif (this.#cache.has(key)) {\n\t\t\treturn this.#peek(key, this.#cache)\n\t\t}\n\n\t\tif (this.#oldCache.has(key)) {\n\t\t\treturn this.#peek(key, this.#oldCache)\n\t\t}\n\t\treturn undefined\n\t}\n\n\tdelete(key: K): boolean {\n\t\tconst deleted = this.#cache.delete(key)\n\t\tif (deleted) {\n\t\t\tthis.#size--\n\t\t}\n\n\t\treturn this.#oldCache.delete(key) || deleted\n\t}\n\n\tclear(): void {\n\t\tthis.#cache.clear()\n\t\tthis.#oldCache.clear()\n\t\tthis.#size = 0\n\t}\n\n\tresize(maxSize: number): void {\n\t\tif (!(maxSize && maxSize > 0)) {\n\t\t\tthrow new TypeError(\"`maxSize` must be a number greater than 0\")\n\t\t}\n\n\t\tconst items = [...this.#entriesAscending()]\n\t\tconst removeCount = items.length - maxSize\n\t\tif (removeCount < 0) {\n\t\t\tthis.#cache = new Map(items)\n\t\t\tthis.#oldCache = new Map()\n\t\t\tthis.#size = items.length\n\t\t} else {\n\t\t\tif (removeCount > 0) {\n\t\t\t\tthis.#emitEvictions(new Map(items.slice(0, removeCount)))\n\t\t\t}\n\n\t\t\tthis.#oldCache = new Map(items.slice(removeCount))\n\t\t\tthis.#cache = new Map()\n\t\t\tthis.#size = 0\n\t\t}\n\n\t\tthis.#maxSize = maxSize\n\t}\n\n\t*entriesDescending(): IterableIterator<[K, V]> {\n\t\tconst cacheItems = [...this.#cache]\n\t\tfor (let i = cacheItems.length - 1; i >= 0; --i) {\n\t\t\tconst item = cacheItems[i]\n\t\t\tif (item) {\n\t\t\t\tconst [key, value] = item\n\t\t\t\tconst deleted = this.#deleteIfExpired(key, value)\n\t\t\t\tif (deleted === false) {\n\t\t\t\t\tyield [key, value.value]\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tconst oldItems = [...this.#oldCache]\n\t\tfor (let i = oldItems.length - 1; i >= 0; --i) {\n\t\t\tconst item = oldItems[i]\n\t\t\tif (item) {\n\t\t\t\tconst [key, value] = item\n\t\t\t\tif (!this.#cache.has(key)) {\n\t\t\t\t\tconst deleted = this.#deleteIfExpired(key, value)\n\t\t\t\t\tif (deleted === false) {\n\t\t\t\t\t\tyield [key, value.value]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t*entriesAscending(): IterableIterator<[K, V]> {\n\t\tfor (const [key, value] of this.#entriesAscending()) {\n\t\t\tyield [key, value.value]\n\t\t}\n\t}\n\n\tget size(): number {\n\t\tif (!this.#size) {\n\t\t\treturn this.#oldCache.size\n\t\t}\n\n\t\tlet oldCacheSize = 0\n\t\tfor (const key of this.#oldCache.keys()) {\n\t\t\tif (!this.#cache.has(key)) {\n\t\t\t\toldCacheSize++\n\t\t\t}\n\t\t}\n\n\t\treturn Math.min(this.#size + oldCacheSize, this.#maxSize)\n\t}\n\n\tget maxSize(): number {\n\t\treturn this.#maxSize\n\t}\n}\n\n// Create a proxy class that delegates to Map for iterator methods\nexport default class QuickLRU<K, V> implements Map<K, V> {\n\treadonly #base: LRUBase<K, V>\n\treadonly #map: Map<K, V>\n\n\tconstructor(options: Options<K, V>) {\n\t\tthis.#base = new LRUBase(options)\n\t\tthis.#map = new Map()\n\t}\n\n\tclear(): void {\n\t\tthis.#base.clear()\n\t\tthis.#map.clear()\n\t}\n\n\tdelete(key: K): boolean {\n\t\treturn this.#base.delete(key)\n\t}\n\n\tforEach(\n\t\tcallbackfn: (value: V, key: K, map: Map<K, V>) => void,\n\t\tthisArg?: unknown\n\t): void {\n\t\tthis.#map.forEach(callbackfn, thisArg)\n\t}\n\n\tget(key: K): V | undefined {\n\t\treturn this.#base.get(key)\n\t}\n\n\thas(key: K): boolean {\n\t\treturn this.#base.has(key)\n\t}\n\n\tset(key: K, value: V): this {\n\t\tthis.#base.set(key, value)\n\t\tthis.#map.set(key, value)\n\t\treturn this\n\t}\n\n\tget size(): number {\n\t\treturn this.#base.size\n\t}\n\n\tget maxSize(): number {\n\t\treturn this.#base.maxSize\n\t}\n\n\tpeek(key: K): V | undefined {\n\t\treturn this.#base.peek(key)\n\t}\n\n\tresize(maxSize: number): void {\n\t\tthis.#base.resize(maxSize)\n\t}\n\n\t*entriesAscending(): IterableIterator<[K, V]> {\n\t\tyield* this.#base.entriesAscending()\n\t}\n\n\t*entriesDescending(): IterableIterator<[K, V]> {\n\t\tyield* this.#base.entriesDescending()\n\t}\n\n\t// Delegate Map iterator methods to the internal Map instance\n\tentries() {\n\t\treturn this.#map.entries()\n\t}\n\n\tkeys() {\n\t\treturn this.#map.keys()\n\t}\n\n\tvalues() {\n\t\treturn this.#map.values()\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.#map[Symbol.iterator]()\n\t}\n\n\tget [Symbol.toStringTag](): string {\n\t\treturn \"QuickLRU\"\n\t}\n}\n\n// Define the cache options schema\nexport interface StatementCacheOptions {\n\tmaxSize: number\n\tmaxAge?: number\n}\n\nexport interface StatementCache {\n\tget(sql: string): StatementSync | undefined\n\tset(sql: string, statement: StatementSync): void\n\tdelete(sql: string): void\n\tclear(): void\n\tgetStats(): CacheStats\n}\n\nexport interface CacheStats {\n\thits: number\n\tmisses: number\n\tsize: number\n\tevictions: number\n\ttotalQueries: number\n}\n\nclass EnhancedStatementCache implements StatementCache {\n\tprivate cache: QuickLRU<string, StatementSync>\n\tprivate stats: CacheStats = {\n\t\thits: 0,\n\t\tmisses: 0,\n\t\tsize: 0,\n\t\tevictions: 0,\n\t\ttotalQueries: 0,\n\t}\n\n\tconstructor(options: StatementCacheOptions) {\n\t\tthis.cache = new QuickLRU({\n\t\t\tmaxSize: options.maxSize,\n\t\t\tmaxAge: options.maxAge,\n\t\t\tonEviction: () => {\n\t\t\t\tthis.stats.evictions++\n\t\t\t},\n\t\t})\n\t}\n\n\tget(sql: string): StatementSync | undefined {\n\t\tthis.stats.totalQueries++\n\t\tconst stmt = this.cache.get(sql)\n\t\tif (stmt) {\n\t\t\tthis.stats.hits++\n\t\t} else {\n\t\t\tthis.stats.misses++\n\t\t}\n\t\treturn stmt\n\t}\n\n\tset(sql: string, statement: StatementSync): void {\n\t\tthis.cache.set(sql, statement)\n\t\tthis.stats.size = this.cache.size\n\t}\n\n\tdelete(sql: string): void {\n\t\tthis.cache.delete(sql)\n\t\tthis.stats.size = this.cache.size\n\t}\n\n\tclear(): void {\n\t\tthis.cache.clear()\n\t\tthis.stats.size = 0\n\t}\n\n\tgetStats(): CacheStats {\n\t\treturn { ...this.stats }\n\t}\n}\n\nexport function createStatementCache(options?: StatementCacheOptions) {\n\tif (!options) {\n\t\treturn undefined\n\t}\n\n\tif (options.maxSize <= 0) {\n\t\t// Add runtime validation since we removed schema validation\n\t\tthrow new TypeError(\"maxSize must be a positive number\")\n\t}\n\n\tif (\n\t\toptions.maxAge !== undefined &&\n\t\t(options.maxAge <= 0)\n\t) {\n\t\tthrow new TypeError(\"maxAge must be a positive number\")\n\t}\n\n\treturn new EnhancedStatementCache(options)\n}\n",
      "metadata": {
        "size": 9933,
        "modified": 1737612272737.8005,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "columns.ts": {
      "content": "import { NodeSqliteError, SqlitePrimaryResultCode } from \"#errors.js\"\nimport type { DataRow } from \"#types\"\nimport { validationErr, type ValidationError } from \"#validate\"\n\n/**\n * SQLite column constraints for table definitions\n */\nexport type BaseConstraint =\n\t| \"PRIMARY KEY\"\n\t| \"AUTOINCREMENT\"\n\t| \"UNIQUE\"\n\t| `CHECK (${string})`\n\t| `FOREIGN KEY REFERENCES ${string} (${string})`\n\t| `DEFAULT ${string}`\n\t| \"NOT NULL\"\n\n/**\n * SQLite storage classes (data types)\n * @see https://www.sqlite.org/datatype3.html\n */\nexport type DataType = \"TEXT\" | \"INTEGER\" | \"REAL\" | \"BLOB\"\n\n/**\n * Patterns for combining data types with constraints based on nullability\n * @template T Field type\n * @template D SQLite data type\n */\nexport type ConstraintPatterns<T, D extends DataType> = undefined extends T\n\t?\n\t\t\t| `${D} ${BaseConstraint}`\n\t\t\t| `${D} ${BaseConstraint} ${Exclude<BaseConstraint, \"NOT NULL\">}`\n\t\t\t| `${D} ${BaseConstraint} ${Exclude<BaseConstraint, \"NOT NULL\">} ${Exclude<BaseConstraint, \"NOT NULL\">}`\n\t:\n\t\t\t| `${D} ${BaseConstraint}`\n\t\t\t| `${D} ${BaseConstraint} ${BaseConstraint}`\n\t\t\t| `${D} ${BaseConstraint} ${BaseConstraint} ${BaseConstraint}`\n\n/**\n * Maps TypeScript types to valid SQLite column definitions with constraints\n * @template T The TypeScript type to map\n */\nexport type ValidColumnTypeMap<T> = T extends string\n\t? ConstraintPatterns<T, \"TEXT\"> | \"TEXT\"\n\t: T extends number\n\t\t?\n\t\t\t\t| ConstraintPatterns<T, \"INTEGER\">\n\t\t\t\t| ConstraintPatterns<T, \"REAL\">\n\t\t\t\t| \"INTEGER\"\n\t\t\t\t| \"REAL\"\n\t\t: T extends boolean\n\t\t\t? ConstraintPatterns<T, \"INTEGER\"> | \"INTEGER\"\n\t\t\t: T extends bigint\n\t\t\t\t? ConstraintPatterns<T, \"INTEGER\"> | \"INTEGER\"\n\t\t\t\t: T extends object | unknown[]\n\t\t\t\t\t?\n\t\t\t\t\t\t\t| ConstraintPatterns<T, \"TEXT\">\n\t\t\t\t\t\t\t| ConstraintPatterns<T, \"BLOB\">\n\t\t\t\t\t\t\t| \"BLOB\"\n\t\t\t\t\t\t\t| \"TEXT\"\n\t\t\t\t\t: never\n\n/**\n * Type-safe column definitions for a table\n * @template T Table row type\n */\nexport type Columns<T extends DataRow> = {\n\t[K in keyof T]?: ValidColumnTypeMap<T[K]>\n}\n\nconst columnRegex = /^(TEXT|INTEGER|REAL|BLOB)(\\s+.+)?$/\n\nexport function validateColumns<T extends DataRow>(\n\tvalue: unknown\n): ValidationError[] {\n\tif (!value || typeof value !== \"object\") {\n\t\treturn [validationErr({ msg: \"Columns must be an object\" })]\n\t}\n\n\tconst errors: ValidationError[] = []\n\tconst columns = value as Record<string, string>\n\n\tfor (const [key, def] of Object.entries(columns)) {\n\t\tif (typeof def !== \"string\") {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: `Column '${key}' definition must be a string`,\n\t\t\t\t\tpath: key,\n\t\t\t\t})\n\t\t\t)\n\t\t\tcontinue\n\t\t}\n\n\t\tif (!columnRegex.test(def.trim())) {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: `Invalid column definition format for '${key}'`,\n\t\t\t\t\tpath: key,\n\t\t\t\t})\n\t\t\t)\n\t\t}\n\t}\n\n\treturn errors\n}\n\nexport function isValidColumns<T extends DataRow>(\n\tvalue: unknown\n): value is Columns<T> {\n\treturn validateColumns<T>(value).length === 0\n}\n\nexport function buildColumnsStatement<T extends DataRow>(\n\tcolumns: Columns<T>\n): string {\n\tconst errors = validateColumns<T>(columns)\n\tif (errors.length > 0) {\n\t\tthrow new NodeSqliteError(\n\t\t\t\"ERR_SQLITE_COLUMNS\",\n\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\"Invalid column definitions\",\n\t\t\terrors.map(e => e.message).join(\"\\n\"),\n\t\t\tundefined\n\t\t)\n\t}\n\n\treturn `(\\n  ${Object.entries(columns)\n\t\t.map(([name, def]) => `${name} ${String(def).trim()}`)\n\t\t.join(\",\\n  \")}\\n)`\n}\n",
      "metadata": {
        "size": 3356,
        "modified": 1737760778420.6938,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "context.test.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport { test, describe } from \"node:test\"\nimport assert from \"node:assert/strict\"\nimport {\n\tcombineContexts,\n\tvalidateContextCombination,\n\tvalidateSqlContext,\n\ttype SqlContext,\n} from \"./context.js\"\n\ntype TestUser = {\n\tid: number\n\tname: string\n\tage: number\n\temail: string\n\tcreatedAt: string\n\tisActive: boolean\n\tmetadata: Record<string, unknown>\n}\n\ndescribe(\"SQL Context Validation\", async () => {\n\tdescribe(\"Basic Structure\", () => {\n\t\ttest(\"accepts empty object\", () => {\n\t\t\tconst context = {}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects non-object values\", () => {\n\t\t\tconst values = [null, undefined, 42, \"string\", true, []]\n\t\t\tfor (const value of values) {\n\t\t\t\tconst errors = validateSqlContext<TestUser>(value)\n\t\t\t\tassert.equal(errors.length, 1)\n\t\t\t\tassert.equal(errors[0].message, \"SqlContext must be an object\")\n\t\t\t}\n\t\t})\n\n\t\ttest(\"rejects unknown properties\", () => {\n\t\t\tconst context = {\n\t\t\t\tunknownProp: \"value\",\n\t\t\t\tanotherUnknown: 123,\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 2)\n\t\t\tassert.ok(errors.every(e => e.message.startsWith(\"Unknown property:\")))\n\t\t})\n\t})\n\n\tdescribe(\"Values and Set Validation\", () => {\n\t\ttest(\"accepts '*' for values\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tvalues: \"*\",\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts valid parameter operators\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tvalues: [\"$name\", \"$age\", \"$email\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts toJson operators\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tvalues: [\"$metadata->json\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts valid JSON columns configuration\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tvalues: [\"*\", { jsonColumns: [\"metadata\"] }],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects invalid parameter operators\", () => {\n\t\t\tconst context = {\n\t\t\t\tvalues: [\"name\", \"no-at-sign\", \"$invalid.wrong\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.ok(errors.length > 0)\n\t\t\tassert.ok(\n\t\t\t\terrors.every(e =>\n\t\t\t\t\te.message.includes(\"Invalid parameter operator format\")\n\t\t\t\t)\n\t\t\t)\n\t\t})\n\n\t\ttest(\"rejects invalid JSON columns configuration\", () => {\n\t\t\tconst context = {\n\t\t\t\tvalues: [\"*\", { wrongKey: [\"metadata\"] }],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.ok(errors.length > 0)\n\t\t})\n\t})\n\n\tdescribe(\"Where Clause Validation\", () => {\n\t\ttest(\"accepts valid single condition\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\twhere: \"age != $age\",\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts IS NULL conditions\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\twhere: \"email IS NULL\",\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts valid compound conditions\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\twhere: [\"age != $age\", \"AND\", \"age != $createdAt\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects invalid conditions\", () => {\n\t\t\tconst invalidConditions = [\n\t\t\t\t\"invalid condition\",\n\t\t\t\t\"age >== $minAge\",\n\t\t\t\t\"name LIKES $pattern\",\n\t\t\t\t[\"age >= $minAge\", \"INVALID_OP\", \"name LIKE $pattern\"],\n\t\t\t]\n\n\t\t\tfor (const condition of invalidConditions) {\n\t\t\t\tconst context = { where: condition }\n\t\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\t\tassert.ok(errors.length > 0)\n\t\t\t}\n\t\t})\n\t})\n\n\tdescribe(\"Order By Validation\", () => {\n\t\ttest(\"accepts valid order by clause\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\torderBy: {\n\t\t\t\t\tname: \"ASC\",\n\t\t\t\t\tage: \"DESC\",\n\t\t\t\t},\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects invalid order directions\", () => {\n\t\t\tconst context = {\n\t\t\t\torderBy: {\n\t\t\t\t\tname: \"ASCENDING\",\n\t\t\t\t\tage: \"DOWN\",\n\t\t\t\t},\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 2)\n\t\t\tassert.ok(\n\t\t\t\terrors.every(e => e.message.includes(\"Order direction must be\"))\n\t\t\t)\n\t\t})\n\t})\n\n\tdescribe(\"Limit and Offset Validation\", () => {\n\t\ttest(\"accepts valid limit and offset\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tlimit: 10,\n\t\t\t\toffset: 20,\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects non-numeric limit and offset\", () => {\n\t\t\tconst context = {\n\t\t\t\tlimit: \"10\",\n\t\t\t\toffset: \"20\",\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 2)\n\t\t\tassert.ok(errors.some(e => e.message.includes(\"limit must be a number\")))\n\t\t\tassert.ok(errors.some(e => e.message.includes(\"offset must be a number\")))\n\t\t})\n\t})\n\n\tdescribe(\"Returning Clause Validation\", () => {\n\t\ttest(\"accepts '*' as returning value\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\treturning: \"*\",\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accepts array of column names\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\treturning: [\"id\", \"name\", \"age\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"rejects invalid returning values\", () => {\n\t\t\tconst invalidReturning = [\n\t\t\t\t42,\n\t\t\t\t{ columns: [\"id\", \"name\"] },\n\t\t\t\t[\"id\", 42, \"name\"],\n\t\t\t]\n\n\t\t\tfor (const returning of invalidReturning) {\n\t\t\t\tconst context = { returning }\n\t\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\t\tassert.ok(errors.length > 0)\n\t\t\t}\n\t\t})\n\t})\n\n\tdescribe(\"Complex Scenarios\", () => {\n\t\ttest(\"accepts valid complex context\", () => {\n\t\t\tconst context: SqlContext<TestUser> = {\n\t\t\t\tvalues: [\"$name\", \"$age\", \"$metadata->json\"],\n\t\t\t\twhere: [\"age != $createdAt\", \"AND\", \"isActive > $age\"],\n\t\t\t\torderBy: { name: \"ASC\", createdAt: \"DESC\" },\n\t\t\t\tlimit: 10,\n\t\t\t\toffset: 20,\n\t\t\t\treturning: [\"id\", \"name\", \"age\"],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.equal(errors.length, 0)\n\t\t})\n\n\t\ttest(\"accumulates multiple errors\", () => {\n\t\t\tconst context = {\n\t\t\t\tvalues: [\"invalid\", 123],\n\t\t\t\twhere: \"invalid where\",\n\t\t\t\torderBy: { name: \"INVALID\" },\n\t\t\t\tlimit: \"10\",\n\t\t\t\treturning: [42],\n\t\t\t}\n\t\t\tconst errors = validateSqlContext<TestUser>(context)\n\t\t\tassert.ok(errors.length > 3, \"Should collect multiple validation errors\")\n\t\t})\n\t})\n})\n\ndescribe(\"Context Combination Validation\", () => {\n\ttest(\"rejects duplicate unique clauses\", () => {\n\t\tconst contexts: SqlContext<TestUser>[] = [\n\t\t\t{ values: [\"$name\", \"$age\"] },\n\t\t\t{ values: [\"$email\"] },\n\t\t]\n\t\tconst errors = validateContextCombination(contexts)\n\t\tassert.equal(errors.length, 1)\n\t})\n\n\ttest(\"rejects incompatible clause combinations\", () => {\n\t\tconst contexts: SqlContext<TestUser>[] = [\n\t\t\t{ values: [\"$name\"] },\n\t\t\t{ set: [\"$age\"] },\n\t\t]\n\t\tconst errors = validateContextCombination(contexts)\n\t\tassert.equal(errors.length, 1)\n\t})\n\n\ttest(\"allows valid combinations\", () => {\n\t\tconst contexts: SqlContext<TestUser>[] = [\n\t\t\t{ where: \"age != $age\" },\n\t\t\t{ orderBy: { name: \"ASC\" } },\n\t\t\t{ limit: 10, offset: 20 },\n\t\t]\n\t\tconst errors = validateContextCombination(contexts)\n\t\tassert.equal(errors.length, 0)\n\t})\n\n\ttest(\"combines where clauses correctly\", () => {\n\t\tconst contexts: SqlContext<TestUser>[] = [\n\t\t\t{ where: \"age != $createdAt\" },\n\t\t\t{ where: \"name LIKE $age\" },\n\t\t]\n\t\tconst combined = combineContexts(contexts)\n\t\tassert.deepEqual(combined.where, [\n\t\t\t\"age != $createdAt\",\n\t\t\t\"AND\",\n\t\t\t\"name LIKE $age\",\n\t\t])\n\t})\n})\n",
      "metadata": {
        "size": 8066,
        "modified": 1737674312476.7097,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "context.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport { validateColumns, type Columns } from \"#columns.js\"\nimport { NodeSqliteError, SqlitePrimaryResultCode } from \"#errors\"\nimport type { ToJson, ParameterOperator, FromJson } from \"#sql\"\nimport type { DataRow } from \"#types\"\nimport { validationErr, type ValidationError } from \"#validate\"\nimport { validateWhereClause, type WhereClause } from \"#where\"\n\nexport type ValueType<P extends DataRow> = ParameterOperator<P> | ToJson<P>\n\nexport type SetOptions<P extends DataRow> =\n\t| ValueType<P>[]\n\t| \"*\"\n\t| [\"*\", { jsonColumns: (keyof P)[] }]\n\nexport type InsertOptions<P extends DataRow> =\n\t| ValueType<P>[]\n\t| \"*\"\n\t| [\"*\", { jsonColumns?: (keyof P)[]; forEach?: boolean }]\n\n// Core SQL context type\nexport type SqlContext<P extends DataRow> = Partial<{\n\tcols: (keyof P | FromJson<P> | ToJson<P>)[] | \"*\"\n\tvalues: InsertOptions<P>\n\tset: SetOptions<P>\n\twhere: WhereClause<P>\n\torderBy: Partial<Record<keyof P, \"ASC\" | \"DESC\">>\n\tlimit: number\n\toffset: number\n\treturning: (keyof P)[] | \"*\"\n\tcolumns: Columns<P>\n}>\n\nexport function validateSqlContext<P extends DataRow>(\n\tvalue: unknown\n): ValidationError[] {\n\tconst errors: ValidationError[] = []\n\n\tif (typeof value !== \"object\" || value === null || Array.isArray(value)) {\n\t\treturn [validationErr({ msg: \"SqlContext must be an object\" })]\n\t}\n\n\tconst context = value as Record<string, unknown>\n\n\tfor (const key in context) {\n\t\tswitch (key) {\n\t\t\tcase \"values\":\n\t\t\tcase \"set\": {\n\t\t\t\tconst valueErrors = validateInsertOrSetOptions<P>(context[key])\n\t\t\t\tif (valueErrors.length > 0) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\t...valueErrors.map(err => ({\n\t\t\t\t\t\t\t...err,\n\t\t\t\t\t\t\tpath: `${key}${err.path ? `.${err.path}` : \"\"}`,\n\t\t\t\t\t\t}))\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcase \"cols\": {\n\t\t\t\tconst value = context[key]\n\t\t\t\tif (value !== \"*\" && !Array.isArray(value)) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\tmsg: \"cols must be '*' or an array\",\n\t\t\t\t\t\t\tpath: \"cols\",\n\t\t\t\t\t\t})\n\t\t\t\t\t)\n\t\t\t\t} else if (Array.isArray(value)) {\n\t\t\t\t\tif (!value.every(item => typeof item === \"string\")) {\n\t\t\t\t\t\terrors.push(\n\t\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\t\tmsg: \"cols array must contain only strings\",\n\t\t\t\t\t\t\t\tpath: \"cols\",\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t)\n\t\t\t\t\t}\n\t\t\t\t\t// Validate format of each column spec\n\t\t\t\t\tvalue.forEach((col, index) => {\n\t\t\t\t\t\tif (!isValidColumnSpec(col)) {\n\t\t\t\t\t\t\terrors.push(\n\t\t\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\t\t\tmsg: \"Invalid column format\",\n\t\t\t\t\t\t\t\t\tpath: `cols[${index}]`,\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tcase \"where\": {\n\t\t\t\tconst whereErrors = validateWhereClause<P>(\n\t\t\t\t\tcontext[key] as WhereClause<P>\n\t\t\t\t)\n\t\t\t\tif (whereErrors.length > 0) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\t...whereErrors.map(err => ({\n\t\t\t\t\t\t\t...err,\n\t\t\t\t\t\t\tpath: `where${err.path ? `.${err.path}` : \"\"}`,\n\t\t\t\t\t\t}))\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tcase \"orderBy\": {\n\t\t\t\tconst orderErrors = validateOrderByClause(context[key])\n\t\t\t\tif (orderErrors.length > 0) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\t...orderErrors.map(err => ({\n\t\t\t\t\t\t\t...err,\n\t\t\t\t\t\t\tpath: `orderBy${err.path ? `.${err.path}` : \"\"}`,\n\t\t\t\t\t\t}))\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tcase \"limit\":\n\t\t\tcase \"offset\":\n\t\t\t\tif (typeof context[key] !== \"number\") {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\tmsg: `${key} must be a number`,\n\t\t\t\t\t\t\tpath: key,\n\t\t\t\t\t\t})\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\tcase \"columns\": {\n\t\t\t\tconst columnErrors = validateColumns<P>(context[key])\n\t\t\t\tif (columnErrors.length > 0) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\t...columnErrors.map(err => ({\n\t\t\t\t\t\t\t...err,\n\t\t\t\t\t\t\tpath: `columns${err.path ? `.${err.path}` : \"\"}`,\n\t\t\t\t\t\t}))\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tcase \"returning\": {\n\t\t\t\tconst value = context[key]\n\t\t\t\tif (value !== \"*\" && !Array.isArray(value)) {\n\t\t\t\t\terrors.push(\n\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\tmsg: \"returning must be '*' or an array\",\n\t\t\t\t\t\t\tpath: \"returning\",\n\t\t\t\t\t\t})\n\t\t\t\t\t)\n\t\t\t\t} else if (Array.isArray(value)) {\n\t\t\t\t\t// Check for non-strings\n\t\t\t\t\tif (!value.every(item => typeof item === \"string\")) {\n\t\t\t\t\t\terrors.push(\n\t\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\t\tmsg: \"returning array must contain only strings\",\n\t\t\t\t\t\t\t\tpath: \"returning\",\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t)\n\t\t\t\t\t}\n\t\t\t\t\t// Check for duplicates\n\t\t\t\t\tconst seen = new Set<string>()\n\t\t\t\t\tconst duplicates = value.filter(item => {\n\t\t\t\t\t\tif (seen.has(item)) {\n\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t}\n\t\t\t\t\t\tseen.add(item)\n\t\t\t\t\t\treturn false\n\t\t\t\t\t})\n\t\t\t\t\tif (duplicates.length > 0) {\n\t\t\t\t\t\terrors.push(\n\t\t\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\t\t\tmsg: `Duplicate columns in RETURNING clause: ${duplicates.join(\", \")}`,\n\t\t\t\t\t\t\t\tpath: \"returning\",\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tdefault:\n\t\t\t\terrors.push(\n\t\t\t\t\tvalidationErr({\n\t\t\t\t\t\tmsg: `Unknown property: ${key}`,\n\t\t\t\t\t\tpath: key,\n\t\t\t\t\t})\n\t\t\t\t)\n\t\t}\n\t}\n\n\treturn errors\n}\n\nfunction isValidColumnSpec(value: string): boolean {\n\treturn (\n\t\t!value.includes(\" \") && // No spaces allowed\n\t\t(value.endsWith(\"->json\") ||\n\t\t\tvalue.endsWith(\"<-json\") ||\n\t\t\t!value.includes(\"->\")) // Basic column or JSON operation\n\t)\n}\n\nfunction validateInsertOrSetOptions<P extends DataRow>(\n\tvalue: unknown\n): ValidationError[] {\n\tif (value === \"*\") {\n\t\treturn []\n\t}\n\n\tif (!Array.isArray(value)) {\n\t\treturn [validationErr({ msg: \"Must be '*' or an array\" })]\n\t}\n\n\t// Check if it's a tuple with configuration\n\tif (value.length === 2 && value[0] === \"*\") {\n\t\tconst [, config] = value\n\t\tif (typeof config !== \"object\" || config === null) {\n\t\t\treturn [\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"Second element must be a configuration object\",\n\t\t\t\t\tpath: \"[1]\",\n\t\t\t\t}),\n\t\t\t]\n\t\t}\n\n\t\t// Check for at least one valid config option\n\t\tif (!(\"jsonColumns\" in config) && !(\"forEach\" in config)) {\n\t\t\treturn [\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"Configuration must include either jsonColumns or forEach\",\n\t\t\t\t\tpath: \"[1]\",\n\t\t\t\t}),\n\t\t\t]\n\t\t}\n\n\t\tif (\n\t\t\t\"jsonColumns\" in config &&\n\t\t\t(!Array.isArray(config.jsonColumns) ||\n\t\t\t\t!config.jsonColumns.every((col: unknown) => typeof col === \"string\"))\n\t\t) {\n\t\t\treturn [\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"jsonColumns must be an array of strings\",\n\t\t\t\t\tpath: \"[1].jsonColumns\",\n\t\t\t\t}),\n\t\t\t]\n\t\t}\n\n\t\tif (\"forEach\" in config && typeof config.forEach !== \"boolean\") {\n\t\t\treturn [\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"forEach must be a boolean value\",\n\t\t\t\t\tpath: \"[1].forEach\",\n\t\t\t\t}),\n\t\t\t]\n\t\t}\n\n\t\treturn []\n\t}\n\n\t// Validate parameter operators array\n\tconst errors: ValidationError[] = []\n\tvalue.forEach((item, index) => {\n\t\tif (typeof item !== \"string\") {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"Parameter operator must be a string\",\n\t\t\t\t\tpath: `[${index}]`,\n\t\t\t\t})\n\t\t\t)\n\t\t} else if (!isValidValueType(item)) {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"Invalid parameter operator format\",\n\t\t\t\t\tpath: `[${index}]`,\n\t\t\t\t})\n\t\t\t)\n\t\t}\n\t})\n\n\treturn errors\n}\n\nfunction validateOrderByClause(value: unknown): ValidationError[] {\n\tif (typeof value !== \"object\" || value === null) {\n\t\treturn [\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"orderBy must be an object\",\n\t\t\t}),\n\t\t]\n\t}\n\n\tconst errors: ValidationError[] = []\n\tfor (const [key, direction] of Object.entries(value)) {\n\t\tif (direction !== \"ASC\" && direction !== \"DESC\") {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: \"Order direction must be 'ASC' or 'DESC'\",\n\t\t\t\t\tpath: key,\n\t\t\t\t})\n\t\t\t)\n\t\t}\n\t}\n\n\treturn errors\n}\n\nfunction isValidValueType(value: string): boolean {\n\treturn (\n\t\tvalue.startsWith(\"$\") &&\n\t\t(value.includes(\".toJson\") ? value.endsWith(\".toJson\") : true)\n\t)\n}\n\nexport function isSqlContext<P extends DataRow>(\n\tvalue: unknown\n): value is SqlContext<P> {\n\treturn validateSqlContext<P>(value).length === 0\n}\n\ntype ContextValidationError = {\n\ttype: \"DUPLICATE_CLAUSE\" | \"INCOMPATIBLE_CLAUSE\" | \"INVALID_COMBINATION\"\n\tmessage: string\n\tclauses?: string[]\n}\n\nexport function validateContextCombination<P extends DataRow>(\n\tcontexts: SqlContext<P>[]\n): ContextValidationError[] {\n\tconst errors: ContextValidationError[] = []\n\n\t// Track which clauses we've seen\n\tconst seenClauses = new Set<keyof SqlContext<P>>()\n\n\t// These clauses can only appear once\n\tconst uniqueClauses = new Set([\n\t\t\"values\",\n\t\t\"set\",\n\t\t\"returning\",\n\t\t\"limit\",\n\t\t\"offset\",\n\t])\n\n\t// Track clause combinations that don't make sense together\n\tconst incompatiblePairs = new Map([\n\t\t[\"values\", new Set([\"set\"])],\n\t\t[\"set\", new Set([\"values\"])],\n\t])\n\n\t// Check for duplicate clauses and track what we've seen\n\tfor (const context of contexts) {\n\t\tfor (const [clause, value] of Object.entries(context)) {\n\t\t\tif (value === undefined) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tconst clauseKey = clause as keyof SqlContext<P>\n\n\t\t\t// Check if this is a unique clause that we've seen before\n\t\t\tif (uniqueClauses.has(clauseKey) && seenClauses.has(clauseKey)) {\n\t\t\t\terrors.push({\n\t\t\t\t\ttype: \"DUPLICATE_CLAUSE\",\n\t\t\t\t\tmessage: `Clause \"${clause}\" cannot appear multiple times in a SQL statement`,\n\t\t\t\t\tclauses: [clause],\n\t\t\t\t})\n\t\t\t}\n\n\t\t\t// Check for incompatible clause combinations\n\t\t\tconst incompatibleWith = incompatiblePairs.get(clause)\n\t\t\tif (incompatibleWith) {\n\t\t\t\tfor (const otherClause of incompatibleWith) {\n\t\t\t\t\tif (seenClauses.has(otherClause as keyof SqlContext<P>)) {\n\t\t\t\t\t\terrors.push({\n\t\t\t\t\t\t\ttype: \"INCOMPATIBLE_CLAUSE\",\n\t\t\t\t\t\t\tmessage: `Clauses \"${clause}\" and \"${otherClause}\" cannot be used together`,\n\t\t\t\t\t\t\tclauses: [clause, otherClause],\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tseenClauses.add(clauseKey)\n\t\t}\n\t}\n\n\treturn errors\n}\n\nexport function combineContexts<P extends DataRow>(\n\tcontexts: SqlContext<P>[]\n): SqlContext<P> {\n\t// First validate the combination\n\tconst errors = validateContextCombination(contexts)\n\tif (errors.length > 0) {\n\t\tthrow new NodeSqliteError(\n\t\t\t\"ERR_SQLITE_CONTEXT\",\n\t\t\tSqlitePrimaryResultCode.SQLITE_MISUSE,\n\t\t\t\"Invalid SQL context combination\",\n\t\t\terrors.map(e => e.message).join(\"\\n\"),\n\t\t\tundefined\n\t\t)\n\t}\n\n\t// Helper function to combine where clauses safely\n\tconst combineWhereClauses = (\n\t\tclause1: WhereClause<P> | undefined,\n\t\tclause2: WhereClause<P> | undefined\n\t): WhereClause<P> | undefined => {\n\t\tif (!clause1) {\n\t\t\treturn clause2\n\t\t}\n\t\tif (!clause2) {\n\t\t\treturn clause1\n\t\t}\n\n\t\tconst clause1Array = Array.isArray(clause1) ? clause1 : [clause1]\n\t\tconst clause2Array = Array.isArray(clause2) ? clause2 : [clause2]\n\n\t\t// Ensure we're not exceeding the maximum allowed conditions\n\t\treturn [...clause1Array, \"AND\", ...clause2Array] as WhereClause<P>\n\t}\n\n\t// Helper function to combine orderBy clauses safely\n\tconst combineOrderByClauses = (\n\t\torderBy1: Partial<Record<keyof P, \"ASC\" | \"DESC\">> | undefined,\n\t\torderBy2: Partial<Record<keyof P, \"ASC\" | \"DESC\">> | undefined\n\t): Partial<Record<keyof P, \"ASC\" | \"DESC\">> | undefined => {\n\t\tif (!orderBy1) {\n\t\t\treturn orderBy2\n\t\t}\n\t\tif (!orderBy2) {\n\t\t\treturn orderBy1\n\t\t}\n\n\t\treturn {\n\t\t\t...orderBy1,\n\t\t\t...orderBy2,\n\t\t} as Partial<Record<keyof P, \"ASC\" | \"DESC\">>\n\t}\n\n\treturn contexts.reduce<SqlContext<P>>(\n\t\t(combined, current) => {\n\t\t\t// Create new object with explicit property assignments\n\t\t\tconst result: SqlContext<P> = {}\n\n\t\t\t// Assign values from combined if they exist\n\t\t\t// sourcery skip: use-braces\n\t\t\tif (combined.values !== undefined) result.values = combined.values\n\t\t\tif (combined.set !== undefined) result.set = combined.set\n\t\t\tif (combined.limit !== undefined) result.limit = combined.limit\n\t\t\tif (combined.offset !== undefined) result.offset = combined.offset\n\t\t\tif (combined.returning !== undefined)\n\t\t\t\tresult.returning = combined.returning\n\n\t\t\t// Assign values from current if they exist\n\t\t\tif (current.values !== undefined) result.values = current.values\n\t\t\tif (current.set !== undefined) result.set = current.set\n\t\t\tif (current.limit !== undefined) result.limit = current.limit\n\t\t\tif (current.offset !== undefined) result.offset = current.offset\n\t\t\tif (current.returning !== undefined) result.returning = current.returning\n\n\t\t\t// Handle special cases with combine functions\n\t\t\tresult.where = combineWhereClauses(combined.where, current.where)\n\t\t\tresult.orderBy = combineOrderByClauses(combined.orderBy, current.orderBy)\n\n\t\t\treturn result\n\t\t},\n\t\t{} as SqlContext<P>\n\t)\n}\n\nexport function buildColsStatement<P extends DataRow>(\n\tcols: (keyof P | FromJson<P> | ToJson<P>)[] | \"*\"\n): string {\n\tif (cols === \"*\") {\n\t\treturn \"*\" // Remove \"SELECT\" prefix\n\t}\n\n\tconst columnsList = cols.map(col => {\n\t\tif (typeof col === \"string\") {\n\t\t\tif (col.endsWith(\"->json\")) {\n\t\t\t\tconst columnName = col.split(\"->\")[0]\n\t\t\t\treturn `jsonb(${columnName})`\n\t\t\t}\n\t\t\tif (col.endsWith(\"<-json\")) {\n\t\t\t\tconst columnName = col.split(\"<-\")[0]\n\t\t\t\treturn `json_extract(${columnName}, '$')`\n\t\t\t}\n\t\t\treturn col\n\t\t}\n\t\treturn String(col)\n\t})\n\n\treturn columnsList.join(\", \") // Remove \"SELECT\" prefix\n}\n",
      "metadata": {
        "size": 12551,
        "modified": 1737781553168.131,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "database.json.test.ts": {
      "content": "import { test, beforeEach, afterEach } from \"node:test\"\nimport assert from \"node:assert/strict\"\nimport { DB } from \"#database\"\n\nlet db: DB\n\nbeforeEach(() => {\n\tdb = new DB({\n\t\tlocation: \":memory:\",\n\t\tenvironment: \"testing\",\n\t})\n\n\tdb.exec(`\n    CREATE TABLE json_test (\n      id INTEGER PRIMARY KEY,\n      simple_object BLOB,\n      nested_object BLOB,\n      array_data BLOB,\n      mixed_data BLOB,\n      nullable_json BLOB\n    )\n  `)\n})\n\nafterEach(() => {\n\tdb.close()\n})\n\ntest(\"handles simple object JSON storage and retrieval\", { only: true }, () => {\n\tinterface SimpleObject {\n\t\tname: string\n\t\tage: number\n\t\tactive: boolean\n\t}\n\n\tconst simpleObject: SimpleObject = {\n\t\tname: \"John\",\n\t\tage: 30,\n\t\tactive: true,\n\t}\n\n\tconst insertData = db.sql<{ data: SimpleObject }>`\n      INSERT INTO json_test (simple_object)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.run({ data: simpleObject })\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT json_extract(simple_object, '$') as data\n      FROM json_test\n    `\n\n\tconst result = getData.all<{ data: SimpleObject }>()\n\tassert.deepEqual(result[0].data, simpleObject)\n})\n\ntest(\"handles nested object JSON storage and retrieval\", () => {\n\tinterface NestedObject {\n\t\tuser: {\n\t\t\tname: string\n\t\t\taddress: {\n\t\t\t\tstreet: string\n\t\t\t\tcity: string\n\t\t\t\tcoords: { lat: number; lng: number }\n\t\t\t}\n\t\t}\n\t\tpreferences: {\n\t\t\ttheme: {\n\t\t\t\tdark: boolean\n\t\t\t\tcolors: { primary: string; secondary: string }\n\t\t\t}\n\t\t}\n\t}\n\n\tconst nestedObject: NestedObject = {\n\t\tuser: {\n\t\t\tname: \"John\",\n\t\t\taddress: {\n\t\t\t\tstreet: \"123 Main St\",\n\t\t\t\tcity: \"Boston\",\n\t\t\t\tcoords: {\n\t\t\t\t\tlat: 42.3601,\n\t\t\t\t\tlng: -71.0589,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tpreferences: {\n\t\t\ttheme: {\n\t\t\t\tdark: true,\n\t\t\t\tcolors: {\n\t\t\t\t\tprimary: \"#000000\",\n\t\t\t\t\tsecondary: \"#ffffff\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tconst insertData = db.sql<{ data: NestedObject }>`\n      INSERT INTO json_test (nested_object)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.run({ data: nestedObject })\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT json_extract(nested_object, '$') as data\n      FROM json_test\n    `\n\n\tconst result = getData.all<{ data: NestedObject }>()\n\tassert.deepEqual(result[0].data, nestedObject)\n})\n\ntest(\"handles multiple row JSON operations\", () => {\n\tinterface RowData {\n\t\tid: number\n\t\tvalue: string\n\t}\n\n\tconst rows: RowData[] = [\n\t\t{ id: 1, value: \"first\" },\n\t\t{ id: 2, value: \"second\" },\n\t]\n\n\tdb.exec(`\n    CREATE TABLE multi_test (\n      id INTEGER PRIMARY KEY,\n      data JSON,\n      created_at TEXT DEFAULT CURRENT_TIMESTAMP\n    )\n  `)\n\n\tconst insertRows = db.sql<{ data: RowData }>`\n      INSERT INTO multi_test (data)\n      VALUES (${\"$data->json\"})\n    `\n\n\tfor (const row of rows) {\n\t\tinsertRows.run({ data: row })\n\t}\n\n\tconst getRows = db.sql<Record<string, never>>`\n    SELECT\n      id,\n      json_extract(data, '$') as data,\n      created_at\n    FROM multi_test\n    ORDER BY id\n  `\n\n\tconst result = getRows.all<{ id: number; data: RowData; created_at: string }>(\n\t\t{}\n\t)\n\tassert.equal(result.length, 2)\n\tassert.deepEqual(result[0].data, rows[0])\n\tassert.deepEqual(result[1].data, rows[1])\n})\n\ntest(\"handles JSON path queries\", () => {\n\tinterface TestData {\n\t\tusers: Array<{\n\t\t\tid: number\n\t\t\tname: string\n\t\t\tsettings: { theme: string }\n\t\t}>\n\t\tconfig: {\n\t\t\tversion: string\n\t\t\tfeatures: {\n\t\t\t\tflag1: boolean\n\t\t\t\tflag2: boolean\n\t\t\t}\n\t\t}\n\t}\n\n\tconst data: TestData = {\n\t\tusers: [\n\t\t\t{ id: 1, name: \"John\", settings: { theme: \"dark\" } },\n\t\t\t{ id: 2, name: \"Jane\", settings: { theme: \"light\" } },\n\t\t],\n\t\tconfig: {\n\t\t\tversion: \"1.0\",\n\t\t\tfeatures: {\n\t\t\t\tflag1: true,\n\t\t\t\tflag2: false,\n\t\t\t},\n\t\t},\n\t}\n\n\tconst insertData = db.sql<{ data: TestData }>`\n      INSERT INTO json_test (nested_object)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.all({ data })\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT\n        json_extract(nested_object, '$') as data,\n        json_extract(nested_object, '$.users[0].name') as first_user_name,\n        json_extract(nested_object, '$.config.version') as version,\n        json_extract(nested_object, '$.users[1].settings.theme') as second_user_theme,\n        json_extract(nested_object, '$.config.features.flag1') as feature_flag\n      FROM json_test\n    `\n\n\tconst result = getData.all<{\n\t\tdata: TestData\n\t\tfirst_user_name: string\n\t\tversion: string\n\t\tsecond_user_theme: string\n\t\tfeature_flag: number\n\t}>()\n\n\tassert.deepEqual(result[0].data, data)\n\tassert.strictEqual(result[0].first_user_name, \"John\")\n\tassert.strictEqual(result[0].version, \"1.0\")\n\tassert.strictEqual(result[0].second_user_theme, \"light\")\n\tassert.strictEqual(result[0].feature_flag, 1)\n})\n\ntest(\"handles array of objects with mixed types\", () => {\n\tinterface ComplexArray {\n\t\titems: Array<{\n\t\t\tid: number\n\t\t\tname: string\n\t\t\tmetadata: {\n\t\t\t\ttags: string[]\n\t\t\t\tcounts: { [key: string]: number }\n\t\t\t\tactive: boolean\n\t\t\t\tlastUpdated: string\n\t\t\t}\n\t\t}>\n\t}\n\n\tconst testData: ComplexArray = {\n\t\titems: [\n\t\t\t{\n\t\t\t\tid: 1,\n\t\t\t\tname: \"Item 1\",\n\t\t\t\tmetadata: {\n\t\t\t\t\ttags: [\"important\", \"urgent\"],\n\t\t\t\t\tcounts: { views: 100, shares: 50 },\n\t\t\t\t\tactive: true,\n\t\t\t\t\tlastUpdated: \"2025-01-20\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tid: 2,\n\t\t\t\tname: \"Item 2\",\n\t\t\t\tmetadata: {\n\t\t\t\t\ttags: [\"archived\"],\n\t\t\t\t\tcounts: { views: 75, shares: 25 },\n\t\t\t\t\tactive: false,\n\t\t\t\t\tlastUpdated: \"2025-01-19\",\n\t\t\t\t},\n\t\t\t},\n\t\t],\n\t}\n\n\tconst insertData = db.sql<{ data: ComplexArray }>`\n      INSERT INTO json_test (array_data)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.run({ data: testData })\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT\n        json_extract(array_data, '$') as full_data,\n        json_extract(array_data, '$.items[0].metadata.tags[0]') as first_tag,\n        json_extract(array_data, '$.items[0].metadata.counts.views') as view_count,\n        json_extract(array_data, '$.items[1].metadata.active') as is_active\n      FROM json_test\n    `\n\n\tconst result = getData.all<{\n\t\tfull_data: ComplexArray\n\t\tfirst_tag: string\n\t\tview_count: number\n\t\tis_active: number\n\t}>()\n\n\tassert.deepEqual(result[0].full_data, testData)\n\tassert.strictEqual(result[0].first_tag, \"important\")\n\tassert.strictEqual(result[0].view_count, 100)\n\tassert.strictEqual(result[0].is_active, 0)\n})\n\ntest(\"handles null and empty JSON values\", () => {\n\tinterface NullableData {\n\t\trequired: string\n\t\toptional?: string\n\t\tnullValue: null\n\t\temptyObject: Record<string, never>\n\t\temptyArray: never[]\n\t}\n\n\tconst testData: NullableData = {\n\t\trequired: \"present\",\n\t\tnullValue: null,\n\t\temptyObject: {},\n\t\temptyArray: [],\n\t}\n\n\tconst insertData = db.sql<{ data: NullableData }>`\n      INSERT INTO json_test (nullable_json)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.run({ data: testData })\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT\n        json_extract(nullable_json, '$') as data,\n        json_extract(nullable_json, '$.optional') as missing_value,\n        json_extract(nullable_json, '$.nullValue') as null_value,\n        json_extract(nullable_json, '$.emptyObject') as empty_object,\n        json_extract(nullable_json, '$.emptyArray') as empty_array\n      FROM json_test\n    `\n\n\tconst result = getData.all<{\n\t\tdata: NullableData\n\t\tmissing_value: unknown\n\t\tnull_value: null\n\t\tempty_object: Record<string, never>\n\t\tempty_array: never[]\n\t}>()\n\n\tassert.deepEqual(result[0].data, testData)\n\tassert.strictEqual(result[0].missing_value, null)\n\tassert.strictEqual(result[0].null_value, null)\n\tassert.deepEqual(result[0].empty_object, {})\n\tassert.deepEqual(result[0].empty_array, [])\n})\n\ntest(\"handles JSON updates\", () => {\n\tinterface UpdateData {\n\t\tcounter: number\n\t\titems: string[]\n\t\tmetadata: {\n\t\t\tlastModified: string\n\t\t\tmodifiedBy: string\n\t\t}\n\t}\n\n\tconst initialData: UpdateData = {\n\t\tcounter: 1,\n\t\titems: [\"item1\"],\n\t\tmetadata: {\n\t\t\tlastModified: \"2025-01-20\",\n\t\t\tmodifiedBy: \"user1\",\n\t\t},\n\t}\n\n\t// Insert initial data\n\tconst insertData = db.sql<{ data: UpdateData }>`\n      INSERT INTO json_test (mixed_data)\n      VALUES (${\"$data->json\"})\n    `\n\n\tinsertData.run({ data: initialData })\n\n\t// Update the JSON data\n\tconst updatedData: UpdateData = {\n\t\tcounter: 2,\n\t\titems: [\"item1\", \"item2\"],\n\t\tmetadata: {\n\t\t\tlastModified: \"2025-01-21\",\n\t\t\tmodifiedBy: \"user2\",\n\t\t},\n\t}\n\n\tconst updateData = db.sql<{ data: UpdateData }>`\n      UPDATE json_test\n      SET mixed_data = ${\"$data->json\"}\n    `\n\n\tupdateData.run({ data: updatedData })\n\n\t// Verify the update\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT json_extract(mixed_data, '$') as data\n      FROM json_test\n    `\n\n\tconst result = getData.all<{ data: UpdateData }>()\n\tassert.deepEqual(result[0].data, updatedData)\n})\n\ntest(\"handles nested JSON array operations\", () => {\n\tinterface NestedArrayData {\n\t\tmatrix: number[][]\n\t\tobjects: Array<{\n\t\t\tid: number\n\t\t\tnested: {\n\t\t\t\tvalues: string[]\n\t\t\t}\n\t\t}>\n\t}\n\n\tconst testData: NestedArrayData = {\n\t\tmatrix: [\n\t\t\t[1, 2, 3],\n\t\t\t[4, 5, 6],\n\t\t\t[7, 8, 9],\n\t\t],\n\t\tobjects: [\n\t\t\t{ id: 1, nested: { values: [\"a\", \"b\"] } },\n\t\t\t{ id: 2, nested: { values: [\"c\", \"d\"] } },\n\t\t],\n\t}\n\n\tconst insertData = db.sql<{ data: NestedArrayData }>`\n      INSERT INTO json_test (array_data)\n      VALUES (${\"$data->json\"})`\n\n\tinsertData.run({\n\t\tdata: testData,\n\t})\n\n\tconst getData = db.sql<Record<string, never>>`\n      SELECT\n        json_extract(array_data, '$') as data,\n        json_extract(array_data, '$.matrix[1][1]') as center_value,\n        json_extract(array_data, '$.objects[1].nested.values[0]') as nested_value\n      FROM json_test`\n\n\tconst result = getData.all<{\n\t\tdata: NestedArrayData\n\t\tcenter_value: number\n\t\tnested_value: string\n\t}>()\n\n\tassert.deepEqual(result[0].data, testData)\n\tassert.strictEqual(result[0].center_value, 5)\n\tassert.strictEqual(result[0].nested_value, \"c\")\n})\n\ntest(\"handles fromJson when querying stored JSON data\", () => {\n\tinterface UserData {\n\t\tname: string\n\t\tsettings: {\n\t\t\ttheme: string\n\t\t\tnotifications: boolean\n\t\t}\n\t}\n\n\tconst userData: UserData = {\n\t\tname: \"John\",\n\t\tsettings: {\n\t\t\ttheme: \"dark\",\n\t\t\tnotifications: true,\n\t\t},\n\t}\n\n\t// First store the JSON data using toJson\n\tconst insertUser = db.sql<{ user_data: UserData }>`\n    INSERT INTO json_test (simple_object)\n    VALUES (${\"$user_data->json\"})`\n\n\tinsertUser.run({\n\t\tuser_data: userData,\n\t})\n\n\t// Now query it back using fromJson\n\tconst getUser = db.sql<Record<string, never>>`\n    SELECT ${\"$simple_object<-json\"} as user_data\n    FROM json_test`\n\n\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\tconst result = getUser.all<any>()\n\tassert.deepEqual(result[0].user_data, userData)\n})\n\ntest(\"handles fromJson with nested JSON fields\", () => {\n\tinterface ComplexData {\n\t\tid: number\n\t\tmetadata: {\n\t\t\ttags: string[]\n\t\t\ttimestamp: string\n\t\t\tnested: {\n\t\t\t\tcount: number\n\t\t\t\tflags: {\n\t\t\t\t\tactive: boolean\n\t\t\t\t\tfeatured: boolean\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tconst testData: ComplexData = {\n\t\tid: 1,\n\t\tmetadata: {\n\t\t\ttags: [\"test\", \"json\"],\n\t\t\ttimestamp: \"2025-01-20\",\n\t\t\tnested: {\n\t\t\t\tcount: 42,\n\t\t\t\tflags: {\n\t\t\t\t\tactive: true,\n\t\t\t\t\tfeatured: false,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// Store the data\n\tconst insertData = db.sql<{ data: ComplexData }>`\n    INSERT INTO json_test (nested_object)\n    VALUES (${\"$data->json\"})`\n\n\tinsertData.run({\n\t\tdata: testData,\n\t})\n\n\t// Query specific nested fields using fromJson\n\tconst getData = db.sql<Record<string, never>>`\n    SELECT\n      ${\"$nested_object<-json\"} as full_data,\n      json(json_extract(nested_object, '$.metadata.tags')) as tags,\n      json(json_extract(nested_object, '$.metadata.nested.flags')) as flags\n    FROM json_test\n`\n\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\tconst result = getData.all<any>()\n\tassert.deepEqual(result[0].full_data, testData)\n\tassert.deepEqual(result[0].tags, [\"test\", \"json\"])\n\tassert.deepEqual(result[0].flags, {\n\t\tactive: true,\n\t\tfeatured: false,\n\t})\n})\n\ntest(\"handles mixed query with multiple fromJson operations\", () => {\n\tinterface UserProfile {\n\t\tname: string\n\t\tpreferences: { theme: string }\n\t}\n\n\tinterface UserMetadata {\n\t\tlastLogin: string\n\t\tdevices: string[]\n\t}\n\n\tconst profile: UserProfile = {\n\t\tname: \"Jane\",\n\t\tpreferences: { theme: \"light\" },\n\t}\n\n\tconst metadata: UserMetadata = {\n\t\tlastLogin: \"2025-01-20\",\n\t\tdevices: [\"desktop\", \"mobile\"],\n\t}\n\n\t// Store both JSON objects\n\tconst insertData = db.sql<{ profile: UserProfile; meta: UserMetadata }>`\n    INSERT INTO json_test (simple_object, nested_object)\n    VALUES (${\"$profile->json\"}, ${\"$meta->json\"})`\n\n\tinsertData.run({\n\t\tprofile,\n\t\tmeta: metadata,\n\t})\n\n\t// Query both JSON fields using fromJson\n\tconst getData = db.sql<Record<string, never>>`\n    SELECT\n      ${\"$simple_object<-json\"} as profile,\n      ${\"$nested_object<-json\"} as metadata\n    FROM json_test`\n\n\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\tconst result = getData.all<any>()\n\tassert.deepEqual(result[0].profile, profile)\n\tassert.deepEqual(result[0].metadata, metadata)\n})\n",
      "metadata": {
        "size": 12783,
        "modified": 1737781157135.9941,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "database.test.ts": {
      "content": "import { test, beforeEach, afterEach } from \"node:test\"\nimport assert from \"node:assert/strict\"\nimport { DB } from \"./database\"\nimport { NodeSqliteError, SqlitePrimaryResultCode } from \"./errors\"\n\nlet db: DB\n\nbeforeEach(() => {\n\tdb = new DB({\n\t\tlocation: \":memory:\",\n\t\tenvironment: \"testing\",\n\t\t// logger: new ConsoleLogger(LogLevel.DEBUG), // Changed to DEBUG level\n\t})\n\n\tdb.exec(\"DROP TABLE IF EXISTS posts;\")\n\tdb.exec(\"DROP TABLE IF EXISTS users;\")\n\n\tdb.exec(`\n      CREATE TABLE users (\n        id INTEGER PRIMARY KEY,\n        name TEXT NOT NULL,\n        age INTEGER NOT NULL,\n        email TEXT UNIQUE\n      );\n    `)\n\n\tdb.exec(`\n      CREATE TABLE posts (\n        id INTEGER PRIMARY KEY,\n        title TEXT NOT NULL,\n        user_id INTEGER,\n        FOREIGN KEY(user_id) REFERENCES users(id)\n      );\n    `)\n})\n\nafterEach(() => {\n\tdb.close()\n})\n\ntest(\"executes basic SELECT query\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tinsertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\tinsertUser.run({\n\t\tname: \"Jane\",\n\t\tage: 25,\n\t\temail: \"jane$example.com\",\n\t})\n\n\tconst users = db.sql<\n\t\t{ minAge: number },\n\t\t{\n\t\t\tname: string\n\t\t\tage: number\n\t\t\temail: string\n\t\t}\n\t>`\n            SELECT name, age, email\n            FROM users\n            WHERE age >= ${\"$minAge\"}\n        `\n\n\tconst results = users.all({\n\t\tminAge: 28,\n\t})\n\n\tassert.equal(results.length, 1)\n\tassert.equal(results[0].name, \"John\")\n\tassert.equal(results[0].age, 30)\n})\n\ntest(\"handles syntax errors\", () => {\n\tconst query = db.sql<Record<string, never>>`SELEC * FORM users`\n\n\tassert.throws(\n\t\t() => query.all(), // Execute the query to trigger the error\n\t\terror =>\n\t\t\terror instanceof NodeSqliteError &&\n\t\t\tNodeSqliteError.fromNodeSqlite(error).getPrimaryResultCode() ===\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR\n\t)\n})\n\ntest(\"handles complex WHERE conditions\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tinsertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\tinsertUser.run({\n\t\tname: \"Jane\",\n\t\tage: 25,\n\t\temail: \"jane$example.com\",\n\t})\n\tinsertUser.run({\n\t\tname: \"Bob\",\n\t\tage: 35,\n\t\temail: \"bob$example.com\",\n\t})\n\n\tconst getUsersQuery = db.sql<{ minAge: number; nameLike: string }>`\n            SELECT * FROM users\n            WHERE age >= ${\"$minAge\"}\n            AND name LIKE ${\"$nameLike\"}\n        `\n\n\tconst results = getUsersQuery.all<{ name: string; age: number }>({\n\t\tminAge: 25,\n\t\tnameLike: \"J%\",\n\t})\n\n\tassert.equal(results.length, 2)\n\tassert.ok(results.every(user => user.name.startsWith(\"J\")))\n})\n\ntest(\"performs INSERT operation\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tconst result = insertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\n\tassert.equal(result.changes, 1)\n\tassert.ok(result.lastInsertRowid > 0)\n})\n\ntest(\"performs UPDATE operation\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tconst inserted = insertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\n\tconst updateUser = db.sql<{ id: number | bigint; newAge: number }>`\n            UPDATE users\n            SET age = ${\"$newAge\"}\n            WHERE id = ${\"$id\"}\n        `\n\n\tconst result = updateUser.run({\n\t\tid: inserted.lastInsertRowid,\n\t\tnewAge: 31,\n\t})\n\n\tassert.equal(result.changes, 1)\n})\n\ntest(\"performs DELETE operation\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tconst inserted = insertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\n\tconst deleteUser = db.sql<{ id: number | bigint }>`\n            DELETE FROM users\n            WHERE id = ${\"$id\"}\n        `\n\n\tconst result = deleteUser.run({ id: inserted.lastInsertRowid })\n\tassert.equal(result.changes, 1)\n})\n\ntest(\"handles unique constraint violations\", () => {\n\tconst insertUser = db.sql<{ name: string; age: number; email: string }>`\n            INSERT INTO users (name, age, email)\n            VALUES (${\"$name\"}, ${\"$age\"}, ${\"$email\"})\n        `\n\n\tinsertUser.run({\n\t\tname: \"John\",\n\t\tage: 30,\n\t\temail: \"john$example.com\",\n\t})\n\n\tassert.throws(\n\t\t() =>\n\t\t\tinsertUser.run({\n\t\t\t\tname: \"Jane\",\n\t\t\t\tage: 25,\n\t\t\t\temail: \"john$example.com\",\n\t\t\t}),\n\t\terror =>\n\t\t\terror instanceof NodeSqliteError &&\n\t\t\terror.message.includes(\"UNIQUE constraint\")\n\t)\n})\n\ntest(\"handles foreign key constraints\", () => {\n\tconst insertPost = db.sql<{ title: string; userId: number }>`\n            INSERT INTO posts (title, user_id)\n            VALUES (${\"$title\"}, ${\"$userId\"})\n        `\n\n\tassert.throws(\n\t\t() =>\n\t\t\tinsertPost.run({\n\t\t\t\ttitle: \"Test Post\",\n\t\t\t\tuserId: 999,\n\t\t\t}),\n\t\terror =>\n\t\t\terror instanceof NodeSqliteError &&\n\t\t\terror.message.includes(\"FOREIGN KEY constraint\")\n\t)\n})\n\ntest(\"enforces NOT NULL constraints\", () => {\n\tconst insertUser = db.sql<{\n\t\tname: string | null\n\t\tage: number\n\t}>`\n            INSERT INTO users (name, age)\n            VALUES (${\"$name\"}, ${\"$age\"})\n        `\n\n\tassert.throws(\n\t\t() =>\n\t\t\tinsertUser.run({\n\t\t\t\tname: null,\n\t\t\t\tage: 30,\n\t\t\t}),\n\t\t{\n\t\t\tname: \"NodeSqliteError\",\n\t\t}\n\t)\n})\n\ntest(\"caches prepared statements\", () => {\n\tconst dbWithCache = new DB({\n\t\tlocation: \":memory:\",\n\t\tstatementCache: { maxSize: 10 },\n\t})\n\n\tconst query = dbWithCache.sql<{ minAge: number }>`\n            SELECT * FROM users\n            WHERE age > ${\"$minAge\"}\n        `\n\n\t// Need to create the table first\n\tdbWithCache.exec(`\n        CREATE TABLE users (\n            id INTEGER PRIMARY KEY,\n            name TEXT NOT NULL,\n            age INTEGER NOT NULL,\n            email TEXT UNIQUE\n        );\n    `)\n\n\tquery.all<unknown[]>({ minAge: 20 })\n\tquery.all<unknown[]>({ minAge: 25 })\n\tquery.all<unknown[]>({ minAge: 30 })\n\n\tconst stats = dbWithCache.getCacheStats()\n\tassert.ok(stats)\n\tassert.ok(stats.hits > 0)\n\n\tdbWithCache.close()\n})\n\ntest(\"clears statement cache\", () => {\n\tconst dbWithCache = new DB({\n\t\tlocation: \":memory:\",\n\t\tstatementCache: { maxSize: 10 },\n\t})\n\n\tdbWithCache.clearStatementCache()\n\tconst stats = dbWithCache.getCacheStats()\n\tassert.ok(stats)\n\tassert.equal(stats.size, 0)\n\n\tdbWithCache.close()\n})\n",
      "metadata": {
        "size": 6715,
        "modified": 1737761584158.8992,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "database.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport { DatabaseSync, type StatementSync } from \"node:sqlite\"\nimport {\n\tNodeSqliteError,\n\tSqlitePrimaryResultCode,\n\tisNodeSqliteError,\n} from \"#errors\"\nimport {\n\tcreateStatementCache,\n\ttype StatementCache,\n\ttype CacheStats,\n} from \"#cache\"\nimport { join } from \"node:path\"\nimport {\n\ttype PragmaConfig,\n\tPragmaDefaults,\n\tgetPragmaStatements,\n} from \"#pragmas\"\nimport { tmpdir } from \"node:os\"\nimport { accessSync, renameSync, unlinkSync } from \"node:fs\"\nimport { type Logger, NoopLogger } from \"#logger\"\nimport {\n\tcreateXStatementSync,\n\tSql,\n\ttype SqlTemplateValues,\n\ttype FormatterConfig,\n} from \"#sql\"\nimport type { CleanupPragmas, DataRow, DBOptions } from \"#types\"\n\n/**\n * Type-safe SQLite database wrapper with prepared statement caching, SQL template literals,\n * and JSON support.\n */\nexport class DB {\n\t#db: DatabaseSync\n\treadonly #statementCache?: StatementCache\n\treadonly #location: string\n\treadonly #logger: Logger\n\treadonly #formatConfig?: FormatterConfig\n\t/**\n\t * Creates a new database connection with optional configuration.\n\t * @param options Database configuration options\n\t * @throws {NodeSqliteError} If database cannot be opened or initialized\n\t */\n\n\tconstructor(options: DBOptions = {}) {\n\t\tconst location = options.location ?? \":memory:\"\n\t\tthis.#location = location\n\t\tthis.#logger = options.logger ?? new NoopLogger()\n\t\tthis.#formatConfig = options.format\n\n\t\tthis.#logger.debug(\"Initializing database\", { location })\n\n\t\ttry {\n\t\t\tthis.#db = new DatabaseSync(location, { open: true })\n\t\t\tthis.#logger.info(\"Database opened successfully\", { location })\n\n\t\t\t// Configure pragmas based on environment and custom settings\n\t\t\tconst environment = options.environment || \"development\"\n\t\t\tthis.#logger.debug(\"Configuring pragmas\", { environment })\n\n\t\t\tconst defaultPragmas = PragmaDefaults[environment]\n\t\t\tconst customPragmas = options.pragma || {}\n\t\t\tconst finalPragmas: PragmaConfig = {\n\t\t\t\t...defaultPragmas,\n\t\t\t\t...customPragmas,\n\t\t\t}\n\t\t\tthis.#configurePragmas(finalPragmas)\n\n\t\t\t// Initialize statement cache if enabled\n\t\t\tif (options.statementCache) {\n\t\t\t\tthis.#logger.debug(\"Initializing statement cache\")\n\t\t\t\tif (typeof options.statementCache === \"object\") {\n\t\t\t\t\tthis.#statementCache = createStatementCache(options.statementCache)\n\t\t\t\t\tthis.#logger.debug(\n\t\t\t\t\t\t\"Created statement cache with custom options\",\n\t\t\t\t\t\toptions.statementCache\n\t\t\t\t\t)\n\t\t\t\t} else {\n\t\t\t\t\tthis.#statementCache = createStatementCache({ maxSize: 1000 })\n\t\t\t\t\tthis.#logger.debug(\"Created statement cache with default options\")\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tthis.#logger.error(\"Failed to initialize database\", error)\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_OPEN\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_CANTOPEN,\n\t\t\t\t\"Cannot open database\",\n\t\t\t\t`Failed to open database at ${location}`,\n\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t)\n\t\t}\n\t}\n\t/**\n\t * Prepares an SQL statement with optional caching.\n\t * @param sql The SQL statement to prepare\n\t * @returns Prepared statement\n\t * @throws {NodeSqliteError} If statement preparation fails\n\t */\n\n\tprepareStatement(sql: string): StatementSync {\n\t\tthis.#logger.debug(\"Preparing statement\", { sql })\n\t\ttry {\n\t\t\tif (this.#statementCache) {\n\t\t\t\tconst cached = this.#statementCache.get(sql)\n\t\t\t\tif (cached) {\n\t\t\t\t\tthis.#logger.trace(\"Statement cache hit\", { sql })\n\t\t\t\t\treturn cached\n\t\t\t\t}\n\t\t\t\tthis.#logger.trace(\"Statement cache miss\", { sql })\n\t\t\t}\n\n\t\t\tconst stmt = this.#db.prepare(sql)\n\t\t\tthis.#logger.trace(\"Statement prepared successfully\", { sql })\n\n\t\t\tif (this.#statementCache) {\n\t\t\t\tthis.#statementCache.set(sql, stmt)\n\t\t\t\tthis.#logger.trace(\"Statement cached\", { sql })\n\t\t\t}\n\n\t\t\treturn stmt\n\t\t} catch (error) {\n\t\t\tif (\n\t\t\t\tthis.#statementCache &&\n\t\t\t\terror instanceof Error &&\n\t\t\t\terror.message.toLowerCase().includes(\"memory\")\n\t\t\t) {\n\t\t\t\tthis.#logger.warn(\"Memory pressure detected, clearing statement cache\")\n\t\t\t\tthis.#statementCache.clear()\n\t\t\t}\n\n\t\t\tthis.#logger.error(\"Failed to prepare statement\", { sql, error })\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_PREPARE\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\"Failed to prepare statement\",\n\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t)\n\t\t}\n\t}\n\t/**\n\t * Creates a type-safe SQL query builder using template literals.\n\t * @param strings SQL template strings\n\t * @param params SQL template parameters and contexts\n\t * @returns Type-safe statement executor\n\t */\n\tsql<P extends DataRow, R = unknown>(\n\t\tstrings: TemplateStringsArray,\n\t\t...params: SqlTemplateValues<P>\n\t) {\n\t\tconst builder = new Sql<P>({\n\t\t\tstrings,\n\t\t\tparamOperators: params,\n\t\t\tformatterConfig: this.#formatConfig,\n\t\t})\n\t\treturn createXStatementSync<P, R>({\n\t\t\tbuild: finalParams => {\n\t\t\t\tconst { sql, namedParams, hasJsonColumns } =\n\t\t\t\t\tbuilder.prepare(finalParams)\n\t\t\t\tconst stmt = this.prepareStatement(sql)\n\t\t\t\treturn { stmt, namedParams, hasJsonColumns }\n\t\t\t},\n\t\t\tprepare: sql => this.prepareStatement(sql),\n\t\t\tsql: builder,\n\t\t})\n\t}\n\n\t/**\n\t * Creates a backup of the database.\n\t * @param filename Path where backup will be saved\n\t * @throws {NodeSqliteError} If backup creation fails\n\t */\n\n\tbackup(filename: string): void {\n\t\tthis.#logger.info(\"Starting database backup\", { filename })\n\t\ttry {\n\t\t\tthis.#db.exec(`VACUUM INTO '${filename}'`)\n\t\t\tthis.#logger.info(\"Database backup completed successfully\", {\n\t\t\t\tfilename,\n\t\t\t})\n\t\t} catch (error) {\n\t\t\tthis.#logger.error(\"Backup failed\", { filename, error })\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_BACKUP\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_CANTOPEN,\n\t\t\t\t\"Cannot create backup file\",\n\t\t\t\t`Failed to create backup at ${filename}. Check permissions and ensure directory exists.`,\n\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t)\n\t\t}\n\t}\n\n\t/**\n\t * Restores database from a backup file.\n\t * @param filename Path to backup file\n\t * @throws {NodeSqliteError} If restore fails or file is inaccessible\n\t */\n\n\trestore(filename: string): void {\n\t\tthis.#logger.info(\"Starting database restore\", { filename })\n\t\ttry {\n\t\t\tif (this.#location === \":memory:\") {\n\t\t\t\tthis.#logger.error(\"Cannot restore in-memory database\")\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_RESTORE\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_MISUSE,\n\t\t\t\t\t\"Cannot restore in-memory database\",\n\t\t\t\t\t\"Restore operation is not supported for in-memory databases\",\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\taccessSync(filename)\n\t\t\t} catch (error) {\n\t\t\t\tthis.#logger.error(\"Backup file inaccessible\", { filename, error })\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_CANTOPEN\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_CANTOPEN,\n\t\t\t\t\t\"Cannot open backup file\",\n\t\t\t\t\t`Failed to restore from ${filename}. File may not exist or be inaccessible.`,\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tthis.#logger.debug(\"Creating temporary backup\")\n\t\t\tthis.close()\n\n\t\t\tconst tempBackup = join(tmpdir(), `temp-${Date.now()}.db`)\n\t\t\ttry {\n\t\t\t\trenameSync(this.#location, tempBackup)\n\t\t\t\tthis.#logger.debug(\"Created temporary backup\", { tempBackup })\n\n\t\t\t\trenameSync(filename, this.#location)\n\t\t\t\tthis.#logger.debug(\"Moved new database into place\")\n\n\t\t\t\tthis.#db = new DatabaseSync(this.#location, { open: true })\n\t\t\t\tthis.#logger.debug(\"Opened restored database\")\n\n\t\t\t\tunlinkSync(tempBackup)\n\t\t\t\tthis.#logger.debug(\"Removed temporary backup\")\n\n\t\t\t\tthis.#logger.info(\"Database restore completed successfully\")\n\t\t\t} catch (error) {\n\t\t\t\tthis.#logger.error(\"Restore failed, attempting rollback\", { error })\n\t\t\t\tif (error instanceof Error && error.message.includes(\"ENOENT\")) {\n\t\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\t\"ERR_SQLITE_CANTOPEN\",\n\t\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_CANTOPEN,\n\t\t\t\t\t\t\"Cannot open backup file\",\n\t\t\t\t\t\t`Failed to restore from ${filename}`,\n\t\t\t\t\t\terror\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tthrow error\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tthrow error instanceof NodeSqliteError\n\t\t\t\t? error\n\t\t\t\t: NodeSqliteError.fromNodeSqlite(\n\t\t\t\t\t\terror instanceof Error ? error : new Error(String(error))\n\t\t\t\t\t)\n\t\t}\n\t}\n\n\t/**\n\t * Executes raw SQL directly.\n\t * @param sql SQL statement to execute\n\t * @throws {NodeSqliteError} If execution fails\n\t */\n\n\texec(sql: string): void {\n\t\ttry {\n\t\t\tthis.#logger.debug(\"Executing raw SQL\", { sql })\n\t\t\tthis.#db.exec(sql)\n\t\t\tthis.#logger.trace(\"Raw SQL executed successfully\", { sql })\n\t\t} catch (error) {\n\t\t\tthis.#logger.error(\"Raw SQL execution failed\", { sql, error })\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_EXEC\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\"Execution failed\",\n\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t)\n\t\t}\n\t}\n\n\t/**\n\t * Retrieves prepared statement cache statistics.\n\t * @returns Cache statistics if caching is enabled, undefined otherwise\n\t */\n\n\tgetCacheStats(): CacheStats | undefined {\n\t\tthis.#logger.debug(\"Retrieving cache statistics\")\n\t\treturn this.#statementCache?.getStats()\n\t}\n\n\t/**\n\t * Clears the prepared statement cache if enabled.\n\t */\n\n\tclearStatementCache(): void {\n\t\tif (this.#statementCache) {\n\t\t\tthis.#logger.debug(\"Clearing statement cache\")\n\t\t\tthis.#statementCache.clear()\n\t\t\tthis.#logger.debug(\"Statement cache cleared\")\n\t\t}\n\t}\n\n\t/**\n\t * Closes database connection and optionally runs cleanup pragmas.\n\t * @param pragmas Optional cleanup operations to perform before closing\n\t */\n\tclose(pragmas?: CleanupPragmas): void {\n\t\tthis.#logger.info(\"Closing database connection\", pragmas)\n\n\t\ttry {\n\t\t\tif (pragmas) {\n\t\t\t\tif (pragmas.optimize) {\n\t\t\t\t\tthis.#db.exec(\"PRAGMA optimize;\")\n\t\t\t\t}\n\t\t\t\tif (pragmas.shrinkMemory) {\n\t\t\t\t\tthis.#db.exec(\"PRAGMA shrink_memory;\")\n\t\t\t\t}\n\t\t\t\tif (pragmas.walCheckpoint) {\n\t\t\t\t\tthis.#db.exec(`PRAGMA wal_checkpoint(${pragmas.walCheckpoint});`)\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tthis.#logger.error(\"Error executing cleanup pragmas\", error)\n\t\t} finally {\n\t\t\tthis.clearStatementCache()\n\t\t\tthis.#db.close()\n\t\t\tthis.#logger.info(\"Database connection closed\")\n\t\t}\n\t}\n\n\t/**\n\t * Configures database pragmas.\n\t * @param config PRAGMA configuration settings\n\t * @throws {NodeSqliteError} If pragma configuration fails\n\t * @private\n\t */\n\n\t#configurePragmas(config: PragmaConfig): void {\n\t\ttry {\n\t\t\tthis.#logger.debug(\"Configuring pragmas\", config)\n\t\t\tconst statements = getPragmaStatements(config)\n\n\t\t\tfor (const stmt of statements) {\n\t\t\t\tthis.#logger.trace(\"Executing pragma statement\", { stmt })\n\t\t\t\tthis.#db.exec(stmt)\n\t\t\t}\n\n\t\t\tthis.#logger.debug(\"Pragma configuration completed\")\n\t\t} catch (error) {\n\t\t\tthis.#logger.error(\"Failed to configure pragmas\", { error })\n\t\t\tif (isNodeSqliteError(error)) {\n\t\t\t\tif (\n\t\t\t\t\tNodeSqliteError.fromNodeSqlite(error).getPrimaryResultCode() ===\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_BUSY\n\t\t\t\t) {\n\t\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\t\"ERR_SQLITE_BUSY\",\n\t\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_BUSY,\n\t\t\t\t\t\t\"Database is locked while configuring pragmas\",\n\t\t\t\t\t\t\"Failed to configure database pragmas: database is locked\",\n\t\t\t\t\t\terror\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tthrow error\n\t\t\t}\n\t\t\tthrow NodeSqliteError.fromNodeSqlite(\n\t\t\t\terror instanceof Error ? error : new Error(String(error))\n\t\t\t)\n\t\t}\n\t}\n}\n",
      "metadata": {
        "size": 11329,
        "modified": 1737761025253.2356,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "errors.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n/**\n * SQLite primary result codes (least significant 8 bits)\n * @see https://www.sqlite.org/rescode.html\n */\nexport enum SqlitePrimaryResultCode {\n\tSQLITE_OK = 0,\n\tSQLITE_ERROR = 1,\n\tSQLITE_INTERNAL = 2,\n\tSQLITE_PERM = 3,\n\tSQLITE_ABORT = 4,\n\tSQLITE_BUSY = 5,\n\tSQLITE_LOCKED = 6,\n\tSQLITE_NOMEM = 7,\n\tSQLITE_READONLY = 8,\n\tSQLITE_INTERRUPT = 9,\n\tSQLITE_IOERR = 10,\n\tSQLITE_CORRUPT = 11,\n\tSQLITE_NOTFOUND = 12,\n\tSQLITE_FULL = 13,\n\tSQLITE_CANTOPEN = 14,\n\tSQLITE_PROTOCOL = 15,\n\tSQLITE_SCHEMA = 17,\n\tSQLITE_CONSTRAINT = 19,\n\tSQLITE_MISMATCH = 20,\n\tSQLITE_MISUSE = 21,\n}\n\n/**\n * Maps error codes to their type strings for better error reporting\n */\nexport const SqliteErrorTypes = {\n\t[SqlitePrimaryResultCode.SQLITE_OK]: \"OK\",\n\t[SqlitePrimaryResultCode.SQLITE_ERROR]: \"ERROR\",\n\t[SqlitePrimaryResultCode.SQLITE_INTERNAL]: \"INTERNAL_ERROR\",\n\t[SqlitePrimaryResultCode.SQLITE_PERM]: \"PERMISSION_DENIED\",\n\t[SqlitePrimaryResultCode.SQLITE_ABORT]: \"OPERATION_ABORTED\",\n\t[SqlitePrimaryResultCode.SQLITE_BUSY]: \"DATABASE_BUSY\",\n\t[SqlitePrimaryResultCode.SQLITE_LOCKED]: \"DATABASE_LOCKED\",\n\t[SqlitePrimaryResultCode.SQLITE_NOMEM]: \"OUT_OF_MEMORY\",\n\t[SqlitePrimaryResultCode.SQLITE_READONLY]: \"DATABASE_READONLY\",\n\t[SqlitePrimaryResultCode.SQLITE_INTERRUPT]: \"OPERATION_INTERRUPTED\",\n\t[SqlitePrimaryResultCode.SQLITE_IOERR]: \"IO_ERROR\",\n\t[SqlitePrimaryResultCode.SQLITE_CORRUPT]: \"DATABASE_CORRUPT\",\n\t[SqlitePrimaryResultCode.SQLITE_NOTFOUND]: \"NOT_FOUND\",\n\t[SqlitePrimaryResultCode.SQLITE_FULL]: \"DATABASE_FULL\",\n\t[SqlitePrimaryResultCode.SQLITE_CANTOPEN]: \"CANNOT_OPEN\",\n\t[SqlitePrimaryResultCode.SQLITE_PROTOCOL]: \"PROTOCOL_ERROR\",\n\t[SqlitePrimaryResultCode.SQLITE_SCHEMA]: \"SCHEMA_CHANGED\",\n\t[SqlitePrimaryResultCode.SQLITE_CONSTRAINT]: \"CONSTRAINT_VIOLATION\",\n\t[SqlitePrimaryResultCode.SQLITE_MISMATCH]: \"TYPE_MISMATCH\",\n\t[SqlitePrimaryResultCode.SQLITE_MISUSE]: \"LIBRARY_MISUSE\",\n} as const\n\nexport type SqliteErrorType =\n\t(typeof SqliteErrorTypes)[keyof typeof SqliteErrorTypes]\n\n/**\n * Error interface for node:sqlite errors\n */\nexport interface NodeSqliteErrorData {\n\tcode: string\n\terrcode: number\n\terrstr: string\n\tmessage: string\n\terrorType: SqliteErrorType\n\toriginalError?: Error\n}\n\n/**\n * Custom error class for node:sqlite errors with enhanced type information\n */\nexport class NodeSqliteError extends Error implements NodeSqliteErrorData {\n\tpublic readonly errorType: SqliteErrorType\n\n\tconstructor(\n\t\tpublic readonly code: string,\n\t\tpublic readonly errcode: number,\n\t\tpublic readonly errstr: string,\n\t\tmessage: string,\n\t\tpublic readonly originalError?: Error\n\t) {\n\t\tsuper(message)\n\t\tthis.name = \"NodeSqliteError\"\n\t\tthis.errorType =\n\t\t\tSqliteErrorTypes[errcode as keyof typeof SqliteErrorTypes] || \"ERROR\"\n\t\tObject.setPrototypeOf(this, NodeSqliteError.prototype)\n\t}\n\n\t/**\n\t * Gets the primary result code (least significant 8 bits)\n\t */\n\tgetPrimaryResultCode(): SqlitePrimaryResultCode {\n\t\treturn this.errcode & 0xff\n\t}\n\n\toverride toString(): string {\n\t\treturn `NodeSqliteError: [${this.errorType}] ${this.message} (code: ${this.code}, errcode: ${this.errcode})`\n\t}\n\n\tstatic fromNodeSqlite(\n\t\terror: Error & {\n\t\t\tcode?: string\n\t\t\terrcode?: number\n\t\t\terrstr?: string\n\t\t}\n\t): NodeSqliteError {\n\t\treturn new NodeSqliteError(\n\t\t\terror.code || \"ERR_SQLITE_ERROR\",\n\t\t\terror.errcode || SqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\terror.errstr || \"unknown error\",\n\t\t\terror.message,\n\t\t\terror\n\t\t)\n\t}\n}\n\nexport function isNodeSqliteError(error: unknown): error is NodeSqliteError {\n\treturn (\n\t\terror instanceof NodeSqliteError ||\n\t\t(error instanceof Error &&\n\t\t\t\"code\" in error &&\n\t\t\t\"errcode\" in error &&\n\t\t\t\"errstr\" in error &&\n\t\t\terror.code === \"ERR_SQLITE_ERROR\")\n\t)\n}\n",
      "metadata": {
        "size": 3814,
        "modified": 1737760007868.8206,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "index.ts": {
      "content": "/**\n * @module @takinprofit/sqlitex\n *\n * A type-safe SQLite query builder and database wrapper for Node.js\n *\n * Features:\n * - Type-safe SQL template literals\n * - Prepared statement caching\n * - JSON column support\n * - Strongly typed table schemas\n * - SQL query composition\n * - Full SQLite PRAGMA configuration\n *\n * @example\n * ```ts\n * import { DB } from '@takinprofit/sqlitex'\n *\n * const db = new DB({ location: ':memory:' })\n *\n * // Type-safe queries\n * const users = db.sql<{id: number}>`\n *   SELECT * FROM users\n *   WHERE id = ${'$id'}\n * `\n * const result = users.get({ id: 1 })\n * ```\n *\n * @see {@link https://github.com/takinprofit/sqlitex/blob/main/README.md|Documentation}\n */\nexport type { WhereClause } from \"#where\"\nexport type { ValidationError } from \"#validate\"\nexport type { CleanupPragmas, DBOptions, SqlFn, DataRow } from \"#types\"\nexport { Sql } from \"#sql\"\nexport type {\n\tXStatementSync,\n\tSqlOptions,\n\tFormatterConfig,\n\tSqlTemplateValues,\n} from \"#sql\"\n\nexport { PragmaDefaults } from \"#pragmas\"\nexport type {\n\tJournalMode,\n\tJournalModes,\n\tSynchronousMode,\n\tSynchronousModes,\n\tTempStore,\n\tTempStores,\n\tLockingMode,\n\tLockingModes,\n} from \"#pragmas\"\n\nexport type { SqlContext } from \"#context\"\n\nexport type {\n\tColumns,\n\tValidColumnTypeMap,\n\tConstraintPatterns,\n\tDataType,\n\tBaseConstraint,\n} from \"#columns\"\n\nexport { DB } from \"#database\"\n\nexport * from \"#logger\"\nexport * from \"#errors\"\n",
      "metadata": {
        "size": 1418,
        "modified": 1737781553168.589,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "logger.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nexport enum LogLevel {\n\tERROR = \"error\",\n\tWARN = \"warn\",\n\tINFO = \"info\",\n\tDEBUG = \"debug\",\n\tTRACE = \"trace\",\n}\n\nexport type LogFn = (message: string, ...meta: unknown[]) => void\n\nexport interface Logger {\n\terror: LogFn\n\twarn: LogFn\n\tinfo: LogFn\n\tdebug: LogFn\n\ttrace: LogFn\n}\n\nexport interface LogMessage {\n\tlevel: LogLevel\n\tmessage: string\n\ttimestamp: string\n\tmeta?: unknown[]\n}\n\n/**\n * Default logger that writes to console with timestamps\n */\nexport class ConsoleLogger implements Logger {\n\t#minLevel: LogLevel\n\n\tconstructor(minLevel: LogLevel = LogLevel.INFO) {\n\t\tthis.#minLevel = minLevel\n\t}\n\n\t#shouldLog(level: LogLevel): boolean {\n\t\tconst levels = Object.values(LogLevel)\n\t\treturn levels.indexOf(level) <= levels.indexOf(this.#minLevel)\n\t}\n\n\t#formatMessage(\n\t\tlevel: LogLevel,\n\t\tmessage: string,\n\t\tmeta: unknown[] = []\n\t): LogMessage {\n\t\treturn {\n\t\t\tlevel,\n\t\t\tmessage,\n\t\t\ttimestamp: new Date().toISOString(),\n\t\t\tmeta: meta.length > 0 ? meta : undefined,\n\t\t}\n\t}\n\n\terror(message: string, ...meta: unknown[]): void {\n\t\tif (this.#shouldLog(LogLevel.ERROR)) {\n\t\t\tconsole.error(this.#formatMessage(LogLevel.ERROR, message, meta))\n\t\t}\n\t}\n\n\twarn(message: string, ...meta: unknown[]): void {\n\t\tif (this.#shouldLog(LogLevel.WARN)) {\n\t\t\tconsole.warn(this.#formatMessage(LogLevel.WARN, message, meta))\n\t\t}\n\t}\n\n\tinfo(message: string, ...meta: unknown[]): void {\n\t\tif (this.#shouldLog(LogLevel.INFO)) {\n\t\t\tconsole.info(this.#formatMessage(LogLevel.INFO, message, meta))\n\t\t}\n\t}\n\n\tdebug(message: string, ...meta: unknown[]): void {\n\t\tif (this.#shouldLog(LogLevel.DEBUG)) {\n\t\t\tconsole.debug(this.#formatMessage(LogLevel.DEBUG, message, meta))\n\t\t}\n\t}\n\n\ttrace(message: string, ...meta: unknown[]): void {\n\t\tif (this.#shouldLog(LogLevel.TRACE)) {\n\t\t\tconsole.trace(this.#formatMessage(LogLevel.TRACE, message, meta))\n\t\t}\n\t}\n}\n\n/**\n * No-op logger that does nothing\n */\nexport class NoopLogger implements Logger {\n\terror = () => {}\n\twarn = () => {}\n\tinfo = () => {}\n\tdebug = () => {}\n\ttrace = () => {}\n}\n",
      "metadata": {
        "size": 2146,
        "modified": 1737443043864.7473,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "order-by.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport type { DataRow } from \"#types\"\nimport { NodeSqliteError, SqlitePrimaryResultCode } from \"#errors\"\n\nexport function buildOrderByStatement<P extends DataRow>(\n\torderBy?: Partial<Record<keyof P, \"ASC\" | \"DESC\">>\n): string {\n\tif (!orderBy || Object.keys(orderBy).length === 0) {\n\t\tthrow new NodeSqliteError(\n\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\"Invalid orderBy configuration\",\n\t\t\t\"OrderBy must be a non-empty object with column names as keys and 'ASC' or 'DESC' as values\",\n\t\t\tundefined\n\t\t)\n\t}\n\n\tconst orderClauses = Object.entries(orderBy).map(([column, direction]) => {\n\t\tif (direction !== \"ASC\" && direction !== \"DESC\") {\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\"Invalid sort direction\",\n\t\t\t\t`Sort direction must be 'ASC' or 'DESC', got '${direction}'`,\n\t\t\t\tundefined\n\t\t\t)\n\t\t}\n\t\treturn `${column} ${direction}`\n\t})\n\n\treturn `ORDER BY ${orderClauses.join(\", \")}`\n}\n",
      "metadata": {
        "size": 1119,
        "modified": 1737761625092.7402,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "pragmas.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\nimport { validationErr, type ValidationError } from \"./validate\"\n\n/**\n * SQLite journal mode settings\n * @see https://www.sqlite.org/pragma.html#pragma_journal_mode\n */\nexport const JournalModes = [\n\t\"DELETE\",\n\t\"TRUNCATE\",\n\t\"PERSIST\",\n\t\"MEMORY\",\n\t\"WAL\",\n\t\"OFF\",\n] as const\nexport type JournalMode = (typeof JournalModes)[number]\n\n/**\n * Synchronization settings for transaction safety\n * @see https://www.sqlite.org/pragma.html#pragma_synchronous\n */\nexport const SynchronousModes = [\"OFF\", \"NORMAL\", \"FULL\", \"EXTRA\"] as const\nexport type SynchronousMode = (typeof SynchronousModes)[number]\n\n/**\n * Temporary storage location settings\n * @see https://www.sqlite.org/pragma.html#pragma_temp_store\n */\nexport const TempStores = [\"DEFAULT\", \"FILE\", \"MEMORY\"] as const\nexport type TempStore = (typeof TempStores)[number]\n\n/**\n * Database locking mode settings\n * @see https://www.sqlite.org/pragma.html#pragma_locking_mode\n */\nexport const LockingModes = [\"NORMAL\", \"EXCLUSIVE\"] as const\nexport type LockingMode = (typeof LockingModes)[number]\n\n/**\n * SQLite PRAGMA configuration options\n */\nexport type PragmaConfig = Partial<{\n\t/** Journal mode for transaction logging */\n\tjournalMode: JournalMode\n\n\t/** Level of transaction synchronization */\n\tsynchronous: SynchronousMode\n\n\t/** Database cache size in kilobytes */\n\tcacheSize: number\n\n\t/** Memory-mapped I/O size in bytes */\n\tmmapSize: number\n\n\t/** Temporary storage location */\n\ttempStore: TempStore\n\n\t/** Database locking mode */\n\tlockingMode: LockingMode\n\n\t/** Busy handler timeout in milliseconds */\n\tbusyTimeout: number\n\n\t/** Enable/disable foreign key constraints */\n\tforeignKeys: boolean\n\n\t/** Write-ahead log auto-checkpoint size */\n\twalAutocheckpoint: number\n\n\t/** Allow/disallow untrusted schema loads */\n\ttrustedSchema: boolean\n}>\n\nexport function validatePragmaConfig(config: unknown): ValidationError[] {\n\tconst errors: ValidationError[] = []\n\n\tif (typeof config !== \"object\" || config === null) {\n\t\treturn [validationErr({ msg: \"PragmaConfig must be an object\" })]\n\t}\n\n\tconst pragmaConfig = config as Record<string, unknown>\n\n\tif (\n\t\t\"journalMode\" in pragmaConfig &&\n\t\t!JournalModes.includes(pragmaConfig.journalMode as JournalMode)\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: `Invalid journal mode: ${pragmaConfig.journalMode}`,\n\t\t\t\tpath: \"journalMode\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"synchronous\" in pragmaConfig &&\n\t\t!SynchronousModes.includes(pragmaConfig.synchronous as SynchronousMode)\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: `Invalid synchronous mode: ${pragmaConfig.synchronous}`,\n\t\t\t\tpath: \"synchronous\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"tempStore\" in pragmaConfig &&\n\t\t!TempStores.includes(pragmaConfig.tempStore as TempStore)\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: `Invalid temp store: ${pragmaConfig.tempStore}`,\n\t\t\t\tpath: \"tempStore\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"lockingMode\" in pragmaConfig &&\n\t\t!LockingModes.includes(pragmaConfig.lockingMode as LockingMode)\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: `Invalid locking mode: ${pragmaConfig.lockingMode}`,\n\t\t\t\tpath: \"lockingMode\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"cacheSize\" in pragmaConfig &&\n\t\ttypeof pragmaConfig.cacheSize !== \"number\"\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"cacheSize must be a number\",\n\t\t\t\tpath: \"cacheSize\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\"mmapSize\" in pragmaConfig && typeof pragmaConfig.mmapSize !== \"number\") {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"mmapSize must be a number\",\n\t\t\t\tpath: \"mmapSize\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"busyTimeout\" in pragmaConfig &&\n\t\ttypeof pragmaConfig.busyTimeout !== \"number\"\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"busyTimeout must be a number\",\n\t\t\t\tpath: \"busyTimeout\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"foreignKeys\" in pragmaConfig &&\n\t\ttypeof pragmaConfig.foreignKeys !== \"boolean\"\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"foreignKeys must be a boolean\",\n\t\t\t\tpath: \"foreignKeys\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"walAutocheckpoint\" in pragmaConfig &&\n\t\ttypeof pragmaConfig.walAutocheckpoint !== \"number\"\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"walAutocheckpoint must be a number\",\n\t\t\t\tpath: \"walAutocheckpoint\",\n\t\t\t})\n\t\t)\n\t}\n\n\tif (\n\t\t\"trustedSchema\" in pragmaConfig &&\n\t\ttypeof pragmaConfig.trustedSchema !== \"boolean\"\n\t) {\n\t\terrors.push(\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"trustedSchema must be a boolean\",\n\t\t\t\tpath: \"trustedSchema\",\n\t\t\t})\n\t\t)\n\t}\n\n\treturn errors\n}\n\n/**\n * Default pragma configurations for different environments\n */\nexport const PragmaDefaults: Record<\n\t\"development\" | \"testing\" | \"production\",\n\tPragmaConfig\n> = {\n\t/**\n\t * Development environment defaults - optimized for development workflow\n\t */\n\tdevelopment: {\n\t\tjournalMode: \"WAL\",\n\t\tsynchronous: \"NORMAL\",\n\t\tcacheSize: -64000, // 64MB cache\n\t\ttempStore: \"MEMORY\",\n\t\tmmapSize: 64000000, // 64MB mmap\n\t\tlockingMode: \"NORMAL\",\n\t\tbusyTimeout: 5000,\n\t\tforeignKeys: true,\n\t\twalAutocheckpoint: 1000,\n\t\ttrustedSchema: true,\n\t},\n\n\t/**\n\t * Testing environment defaults - optimized for in-memory testing\n\t */\n\ttesting: {\n\t\tjournalMode: \"WAL\",\n\t\tsynchronous: \"OFF\", // Less durable but faster for testing\n\t\tcacheSize: -32000, // 32MB cache is enough for testing\n\t\ttempStore: \"MEMORY\",\n\t\tlockingMode: \"EXCLUSIVE\", // Reduce lock conflicts\n\t\tbusyTimeout: 5000,\n\t\tforeignKeys: true,\n\t\twalAutocheckpoint: 1000,\n\t\ttrustedSchema: true,\n\t},\n\n\t/**\n\t * Production environment defaults - optimized for durability and performance\n\t */\n\tproduction: {\n\t\tjournalMode: \"WAL\",\n\t\tsynchronous: \"NORMAL\",\n\t\tcacheSize: -64000, // 64MB cache\n\t\ttempStore: \"MEMORY\",\n\t\tmmapSize: 268435456, // 256MB mmap\n\t\tlockingMode: \"NORMAL\",\n\t\tbusyTimeout: 10000,\n\t\tforeignKeys: true,\n\t\twalAutocheckpoint: 1000,\n\t\ttrustedSchema: false, // Safer default for production\n\t},\n}\n\n/**\n * Generates SQLite PRAGMA statements from configuration\n */\nexport function getPragmaStatements(config: PragmaConfig): string[] {\n\tconst statements: string[] = []\n\n\tif (config.journalMode) {\n\t\tstatements.push(`PRAGMA journal_mode=${config.journalMode};`)\n\t}\n\n\tif (config.synchronous) {\n\t\tstatements.push(`PRAGMA synchronous=${config.synchronous};`)\n\t}\n\n\tif (config.cacheSize !== undefined) {\n\t\tstatements.push(`PRAGMA cache_size=${config.cacheSize};`)\n\t}\n\n\tif (config.mmapSize !== undefined) {\n\t\tstatements.push(`PRAGMA mmap_size=${config.mmapSize};`)\n\t}\n\n\tif (config.tempStore) {\n\t\tstatements.push(`PRAGMA temp_store=${config.tempStore};`)\n\t}\n\n\tif (config.lockingMode) {\n\t\tstatements.push(`PRAGMA locking_mode=${config.lockingMode};`)\n\t}\n\n\tif (config.busyTimeout !== undefined) {\n\t\tstatements.push(`PRAGMA busy_timeout=${config.busyTimeout};`)\n\t}\n\n\tif (config.foreignKeys !== undefined) {\n\t\tstatements.push(`PRAGMA foreign_keys=${config.foreignKeys ? \"ON\" : \"OFF\"};`)\n\t}\n\n\tif (config.walAutocheckpoint !== undefined) {\n\t\tstatements.push(`PRAGMA wal_autocheckpoint=${config.walAutocheckpoint};`)\n\t}\n\n\tif (config.trustedSchema !== undefined) {\n\t\tstatements.push(\n\t\t\t`PRAGMA trusted_schema=${config.trustedSchema ? \"ON\" : \"OFF\"};`\n\t\t)\n\t}\n\n\treturn statements\n}\n",
      "metadata": {
        "size": 7101,
        "modified": 1737759829588.901,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "sql.compose.test.ts": {
      "content": "import { test, beforeEach, afterEach } from \"node:test\"\nimport assert from \"node:assert/strict\"\nimport { DB } from \"#database\"\nimport { isNodeSqliteError } from \"#errors\"\n\nlet db: DB\n\nbeforeEach(() => {\n\tdb = new DB({ location: \":memory:\" })\n\tdb.exec(`\n    CREATE TABLE users (\n      id INTEGER PRIMARY KEY,\n      name TEXT NOT NULL,\n      email TEXT UNIQUE,\n      age INTEGER,\n      settings JSON,\n      metadata JSON,\n      active BOOLEAN DEFAULT true,\n      created_at TEXT DEFAULT CURRENT_TIMESTAMP\n    );\n\n    CREATE TABLE posts (\n      id INTEGER PRIMARY KEY,\n      user_id INTEGER,\n      title TEXT NOT NULL,\n      metadata JSON,\n      FOREIGN KEY(user_id) REFERENCES users(id)\n    );\n  `)\n})\n\nafterEach(() => {\n\tdb.close()\n})\n\ntest(\"concatenates simple strings\", () => {\n\tlet query = db.sql`SELECT * FROM users`\n\tquery = query.sql`WHERE id = ${\"$id\"}`\n\n\tassert.equal(\n\t\tquery.sourceSQL({ id: 1 }).trim(),\n\t\t\"SELECT *\\nFROM users\\nWHERE id = $id\"\n\t)\n})\n\ntest(\"maintains proper sql spacing with multiple concatenations\", () => {\n\tlet query = db.sql`SELECT * FROM users`\n\tquery = query.sql`WHERE age > ${\"$age\"}`\n\tquery = query.sql` AND active = ${\"$active\"}`\n\n\tassert.equal(\n\t\tquery.sourceSQL({ age: 21, active: true }).trim(),\n\t\t\"SELECT *\\nFROM users\\nWHERE age > $age\\n  AND active = $active\"\n\t)\n})\n\ntest(\"correctly handles JSON operations\", () => {\n\tlet query = db.sql`INSERT INTO users (name, settings) VALUES`\n\tquery = query.sql`(${\"$name\"}, ${\"$settings->json\"})`\n\n\tassert.equal(\n\t\tquery\n\t\t\t.sourceSQL({\n\t\t\t\tname: \"test\",\n\t\t\t\tsettings: { theme: \"dark\" },\n\t\t\t})\n\t\t\t.trim(),\n\t\t\"INSERT INTO users (name, settings)\\nVALUES ($name, jsonb($settings))\"\n\t)\n})\n\ntest(\"concatenates multiple SQL fragments with contexts\", () => {\n\tlet query = db.sql`SELECT * FROM users`\n\tquery = query.sql`${{\n\t\twhere: \"age > $age\",\n\t\torderBy: { name: \"ASC\" },\n\t\tlimit: 10,\n\t}}`\n\n\tassert.equal(\n\t\tquery.sourceSQL({ age: 21 }).trim(),\n\t\t\"SELECT *\\nFROM users\\nWHERE age > $age\\nORDER BY name ASC\\nLIMIT 10\"\n\t)\n})\n\ntest(\"preserves SQL context validation\", () => {\n\tassert.throws(() => {\n\t\tlet query = db.sql`SELECT * FROM users`\n\t\tquery = query.sql`${\n\t\t\t{\n\t\t\t\twhere: \"INVALID\",\n\t\t\t\torderBy: { name: \"WRONG\" },\n\t\t\t\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\t\t\t} as any\n\t\t}`\n\t\tquery.sourceSQL()\n\t}, isNodeSqliteError)\n})\n\ntest(\"maintains parameter references through concatenation\", () => {\n\tlet query = db.sql`SELECT * FROM users WHERE`\n\tquery = query.sql`age BETWEEN ${\"$min\"} AND ${\"$max\"}`\n\n\tassert.equal(\n\t\tquery.sourceSQL({ min: 20, max: 30 }).trim(),\n\t\t\"SELECT *\\nFROM users\\nWHERE age BETWEEN $min AND $max\"\n\t)\n})\n\ntest(\"builds complex SELECT with context columns\", () => {\n\tlet query = db.sql`SELECT ${{ cols: [\"users.id\", \"users.name\", \"users.metadata<-json\"] }} FROM users`\n\tquery = query.sql`INNER JOIN posts ON user_id = users.id`\n\tquery = query.sql`${\n\t\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\t\t{ where: \"age > $minAge\" } as any\n\t}`\n\tquery = query.sql`${\n\t\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\t\t{ orderBy: { created_at: \"DESC\" }, limit: 5 } as any\n\t}`\n\n\tassert.equal(\n\t\tquery\n\t\t\t// biome-ignore lint/suspicious/noExplicitAny: <explanation>\n\t\t\t.sourceSQL({ minAge: 21 } as any)\n\t\t\t.trim(),\n\t\t\"SELECT users.id,\\n  users.name,\\n  json_extract(users.metadata, '$')\\nFROM users\\n  INNER JOIN posts ON user_id = users.id\\nWHERE age > $minAge\\nORDER BY created_at DESC\\nLIMIT 5\"\n\t)\n})\n\ntest(\"builds CTE with complex SELECT\", () => {\n\tlet query = db.sql`WITH filtered_users AS (`\n\tquery = query.sql`SELECT ${{ cols: [\"id\", \"name\", \"metadata<-json\"] }}`\n\tquery = query.sql`FROM users`\n\tquery = query.sql`${{ where: \"age > $minAge\", limit: 100 }})`\n\tquery = query.sql`SELECT ${{ cols: [\"id\", \"name\"] }} FROM filtered_users`\n\tquery = query.sql`${{ orderBy: { name: \"ASC\" } }}`\n\n\tassert.equal(\n\t\tquery.sourceSQL({ minAge: 21 }).trim(),\n\t\t\"WITH filtered_users AS (\\n  SELECT id,\\n    name,\\n    json_extract(metadata, '$')\\n  FROM users\\n  WHERE age > $minAge\\n  LIMIT 100\\n)\\nSELECT id,\\n  name\\nFROM filtered_users\\nORDER BY name ASC\"\n\t)\n})\n\ntest(\"builds UPDATE with column list\", () => {\n\tlet query = db.sql`UPDATE users`\n\tquery = query.sql`${{\n\t\tset: [\"$name\", \"$email\", \"$metadata->json\"],\n\t\twhere: \"id = $id\",\n\t\treturning: [\"id\", \"email\"],\n\t}}`\n\n\tassert.equal(\n\t\tquery\n\t\t\t.sourceSQL({\n\t\t\t\tid: 1,\n\t\t\t\tname: \"Test\",\n\t\t\t\temail: \"test@example.com\",\n\t\t\t\tmetadata: { updated: true },\n\t\t\t})\n\t\t\t.trim(),\n\t\t\"UPDATE users\\nSET name = $name,\\n  email = $email,\\n  metadata = jsonb($metadata)\\nWHERE id = $id\\nRETURNING id,\\n  email\"\n\t)\n})\n\ntest(\"builds complex INSERT with subselect and CTE\", () => {\n\tlet query = db.sql`WITH active_users AS (`\n\tquery = query.sql`SELECT ${{ cols: [\"id\", \"metadata<-json\"] }}`\n\tquery = query.sql`FROM users`\n\tquery = query.sql`${{ where: \"active = $active\" }})`\n\tquery = query.sql`INSERT INTO posts (user_id, metadata)`\n\tquery = query.sql`SELECT id, ${\"$newMeta->json\"}`\n\tquery = query.sql`FROM active_users`\n\tquery = query.sql`${{ returning: \"*\" }}`\n\n\tassert.equal(\n\t\tquery\n\t\t\t.sourceSQL({\n\t\t\t\tactive: true,\n\t\t\t\tnewMeta: { type: \"post\" },\n\t\t\t})\n\t\t\t.trim(),\n\t\t\"WITH active_users AS (\\n  SELECT id,\\n    json_extract(metadata, '$')\\n  FROM users\\n  WHERE active = $active\\n)\\nINSERT INTO posts (user_id, metadata)\\nSELECT id,\\n  jsonb($newMeta)\\nFROM active_users\\nRETURNING *\"\n\t)\n})\n",
      "metadata": {
        "size": 5360,
        "modified": 1737761673869.3455,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "sql.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n// noinspection t\n\nimport {\n\tbuildColsStatement,\n\tisSqlContext,\n\ttype SqlContext,\n\tvalidateContextCombination,\n\tvalidateSqlContext,\n} from \"#context\"\nimport { NodeSqliteError, SqlitePrimaryResultCode } from \"#errors\"\nimport { buildSetStatement, buildValuesStatement } from \"#values\"\nimport type { Primitive } from \"type-fest\"\nimport type {\n\tStatementResultingChanges,\n\tStatementSync,\n\tSupportedValueType,\n} from \"node:sqlite\"\nimport type { DataRow } from \"#types\"\nimport { buildWhereStatement } from \"#where.js\"\nimport sqlFormatter from \"@sqltools/formatter\"\nimport { buildOrderByStatement } from \"#order-by\"\nimport { buildColumnsStatement } from \"#columns\"\nimport type { Config } from \"@sqltools/formatter/lib/core/types\"\nimport stringify from \"#stringify\"\n\n/**\n * Represents a parameter operator that references a property of type P\n */\nexport type ParameterOperator<P extends DataRow> = `$${keyof P & string}`\n\n// Step 2: Get keys of non-primitive values\ntype NonPrimitiveKeys<T> = {\n\t[K in keyof T]: T[K] extends Primitive ? never : K\n}[keyof T]\n\n/**\n * Represents a parameter operator that converts a property to JSON\n * Only allows non-primitive values to be converted to JSON\n */\nexport type ToJson<P extends DataRow> =\n\t`$${NonPrimitiveKeys<P> & string}${\"->json\"}`\n\n/**\n * Represents a parameter operator that parses a property from JSON\n * Only allows non-primitive values to be parsed from JSON\n */\nexport type FromJson<P extends DataRow> =\n\t`$${NonPrimitiveKeys<P> & string}${\"<-json\"}` // only supports json_extract\n/**\n * Union type of all possible parameter operators\n */\nexport type ParamValue<P extends DataRow> =\n\t| ParameterOperator<P>\n\t| ToJson<P>\n\t| FromJson<P>\n\nfunction toSupportedValue(value: unknown): SupportedValueType {\n\tif (\n\t\tvalue === null ||\n\t\ttypeof value === \"string\" ||\n\t\ttypeof value === \"number\" ||\n\t\ttypeof value === \"bigint\" ||\n\t\tvalue instanceof Uint8Array\n\t) {\n\t\treturn value as SupportedValueType\n\t}\n\treturn String(value)\n}\n/**\n * Parameter values and contexts that can be used in SQL template literals\n */\nexport type SqlTemplateValues<P extends DataRow> = ReadonlyArray<\n\tParamValue<P> | SqlContext<P>\n>\n\n/**\n * Configuration for SQL formatting\n */\nexport type FormatterConfig =\n\t| false\n\t| {\n\t\t\t/** Indentation string (default: two spaces) */\n\t\t\tindent?: string\n\n\t\t\t/** Case for SQL keywords */\n\t\t\treservedWordCase?: \"upper\" | \"lower\"\n\n\t\t\t/** Lines between queries */\n\t\t\tlinesBetweenQueries?: number | \"preserve\"\n\t  }\n\n/**\n * Options for initializing SQL builder\n */\nexport type SqlOptions<P extends DataRow> = {\n\tstrings: readonly string[]\n\tparamOperators: SqlTemplateValues<P>\n\tformatterConfig?: FormatterConfig\n\tgeneratedSql?: string\n}\n\nexport class Sql<P extends DataRow> {\n\treadonly strings: readonly string[]\n\treadonly paramOperators: SqlTemplateValues<P>\n\n\treadonly formatterConfig?: Readonly<Config> | false\n\t#generatedSql = \"\"\n\n\t#params: P = {} as P\n\n\tconstructor({\n\t\tstrings,\n\t\tparamOperators,\n\t\tgeneratedSql,\n\t\tformatterConfig,\n\t}: SqlOptions<P>) {\n\t\tthis.strings = strings\n\t\tthis.paramOperators = paramOperators\n\n\t\tif (formatterConfig === false) {\n\t\t\tthis.formatterConfig = false\n\t\t} else {\n\t\t\tthis.formatterConfig = {\n\t\t\t\tindent: \"  \",\n\t\t\t\treservedWordCase: \"upper\",\n\t\t\t\tlinesBetweenQueries: 1,\n\t\t\t\t...formatterConfig,\n\t\t\t\tlanguage: \"sql\",\n\t\t\t}\n\t\t}\n\n\t\tthis.#generatedSql = generatedSql ? `${generatedSql} ` : \"\"\n\t}\n\n\t#fmt(sql: string): string {\n\t\tif (this.formatterConfig) {\n\t\t\treturn sqlFormatter.format(sql, this.formatterConfig)\n\t\t}\n\t\treturn sql\n\t}\n\n\t#contextToSql(context: SqlContext<P>): string {\n\t\tconst parts: string[] = []\n\n\t\tif (context.cols) {\n\t\t\tparts.push(buildColsStatement(context.cols))\n\t\t}\n\n\t\t// Columns statement comes first\n\t\tif (context.columns) {\n\t\t\tparts.push(buildColumnsStatement(context.columns))\n\t\t}\n\n\t\t// Values and Set come next\n\t\tif (context.values) {\n\t\t\tparts.push(buildValuesStatement(context.values, this.#params))\n\t\t}\n\t\tif (context.set) {\n\t\t\tparts.push(buildSetStatement(context.set, this.#params))\n\t\t}\n\n\t\t// Rest remains the same\n\t\tif (context.where) {\n\t\t\tparts.push(buildWhereStatement(context.where))\n\t\t}\n\t\tif (context.orderBy) {\n\t\t\tparts.push(buildOrderByStatement(context.orderBy))\n\t\t}\n\t\tif (context.limit !== undefined) {\n\t\t\tparts.push(`LIMIT ${context.limit}`)\n\t\t\tif (context.offset !== undefined) {\n\t\t\t\tparts.push(`OFFSET ${context.offset}`)\n\t\t\t}\n\t\t} else if (context.offset !== undefined) {\n\t\t\tparts.push(\"LIMIT -1\")\n\t\t\tparts.push(`OFFSET ${context.offset}`)\n\t\t}\n\t\tif (context.returning) {\n\t\t\tparts.push(\n\t\t\t\tcontext.returning === \"*\"\n\t\t\t\t\t? \"RETURNING *\"\n\t\t\t\t\t: `RETURNING ${context.returning.join(\", \")}`\n\t\t\t)\n\t\t}\n\t\treturn parts.join(\"\\n\")\n\t}\n\n\t// SQL property update\n\tget sql(): string {\n\t\t// Start with any previously generated SQL\n\t\tlet result = this.#generatedSql\n\n\t\t// Add the first string segment of the current template\n\t\tresult += this.strings[0]\n\t\tfor (let i = 0; i < this.paramOperators.length; i++) {\n\t\t\tconst op = this.paramOperators[i]\n\n\t\t\tif (isSqlContext<P>(op)) {\n\t\t\t\tconst contextSql = this.#contextToSql(op)\n\t\t\t\tresult += contextSql + this.strings[i + 1]\n\t\t\t} else if (typeof op === \"string\") {\n\t\t\t\tif (op.endsWith(\"->json\")) {\n\t\t\t\t\tconst columnName = op.split(\"->\")[0]\n\t\t\t\t\tresult += `jsonb(${columnName}) ${this.strings[i + 1]}`\n\t\t\t\t} else if (op.endsWith(\"<-json\")) {\n\t\t\t\t\tconst columnName = op.split(\"<-\")[0].substring(1)\n\t\t\t\t\tresult += `json_extract(${columnName}, '$') ${this.strings[i + 1]}`\n\t\t\t\t} else {\n\t\t\t\t\tresult += `${op} ${this.strings[i + 1]}`\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tconst ret = this.#fmt(result.trim())\n\t\tconsole.log(`SQL: ${ret}`)\n\t\treturn ret\n\t}\n\n\tget hasJsonColumns(): boolean {\n\t\tconst { sql } = this\n\t\treturn (\n\t\t\tsql.includes(\"json_extract\") ||\n\t\t\tsql.includes(\"json(\") ||\n\t\t\tsql.includes(\"jsonb(\") ||\n\t\t\tsql.includes(\"json_array\") ||\n\t\t\tsql.includes(\"json_object\") ||\n\t\t\tsql.includes(\"json_type\") ||\n\t\t\tsql.includes(\"json_valid\") ||\n\t\t\tsql.includes(\"json_patch\") ||\n\t\t\tsql.includes(\"json_group_array\") ||\n\t\t\tsql.includes(\"json_group_object\") ||\n\t\t\tsql.includes(\"json_tree\") ||\n\t\t\tsql.includes(\"json_each\") ||\n\t\t\tsql.includes(\"->\") ||\n\t\t\tsql.includes(\"->>\")\n\t\t)\n\t}\n\n\t#toNamedParams(): Record<string, SupportedValueType> {\n\t\tconst namedParams: Record<string, SupportedValueType> = {}\n\n\t\tfor (const op of this.paramOperators) {\n\t\t\t// noinspection SuspiciousTypeOfGuard\n\t\t\tif (typeof op !== \"string\" || op.endsWith(\"<-json\")) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tconst paramName = op.split(\"->\")[0].substring(1)\n\t\t\tconst value = this.#params[paramName]\n\n\t\t\tif (value === undefined) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Missing parameter\",\n\t\t\t\t\t`Parameter '${paramName}' is undefined`,\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tif (op.endsWith(\"->json\")) {\n\t\t\t\tif (\n\t\t\t\t\ttypeof value !== \"object\" &&\n\t\t\t\t\t!Array.isArray(value) &&\n\t\t\t\t\tvalue !== null\n\t\t\t\t) {\n\t\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\t\"Invalid parameter\",\n\t\t\t\t\t\t`Parameter '${paramName}' must be an object or array for JSON conversion`,\n\t\t\t\t\t\tundefined\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tnamedParams[`$${paramName}`] = stringify(value)\n\t\t\t} else {\n\t\t\t\tnamedParams[`$${paramName}`] = toSupportedValue(value)\n\t\t\t}\n\t\t}\n\n\t\treturn namedParams\n\t}\n\n\t// In Sql class\n\tprepare(params: P): {\n\t\tsql: string\n\t\tnamedParams: Record<string, SupportedValueType>\n\t\thasJsonColumns: boolean\n\t} {\n\t\tthis.#params = params\n\n\t\tconst contexts = this.paramOperators.filter(\n\t\t\t(op): op is SqlContext<P> => typeof op === \"object\" && !Array.isArray(op)\n\t\t)\n\n\t\tconst validationErrors = contexts.flatMap(context =>\n\t\t\tvalidateSqlContext<P>(context)\n\t\t)\n\n\t\tif (validationErrors.length > 0) {\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_CONTEXT\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_MISUSE,\n\t\t\t\t\"Invalid SQL context\",\n\t\t\t\tvalidationErrors.map(e => e.message).join(\"\\n\"),\n\t\t\t\tundefined\n\t\t\t)\n\t\t}\n\n\t\tconst combinationErrors = validateContextCombination(contexts)\n\n\t\tif (combinationErrors.length > 0) {\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_CONTEXT\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_MISUSE,\n\t\t\t\t\"Invalid SQL context combination\",\n\t\t\t\tcombinationErrors.map(e => e.message).join(\"\\n\"),\n\t\t\t\tundefined\n\t\t\t)\n\t\t}\n\n\t\treturn {\n\t\t\tsql: this.sql,\n\t\t\tnamedParams: this.#toNamedParams(),\n\t\t\thasJsonColumns: this.hasJsonColumns,\n\t\t}\n\t}\n}\n\ntype SingleRow<P extends DataRow> = {\n\t[K in keyof P]: P[K]\n}\n\n// Type for values params that can be single row or multiple rows\ntype ValuesParam<P extends DataRow> =\n\t| SingleRow<P>\n\t| SingleRow<P>[]\n\t| Set<SingleRow<P>>\n\n/**\n * Interface for prepared SQL statements with type safety and chaining support.\n * @template P Type of parameters object\n * @template RET Type of returned rows\n */\nexport interface XStatementSync<P extends DataRow, RET = unknown> {\n\t/** Execute query and return all result rows */\n\tall<R = RET>(params?: ValuesParam<P>): R[]\n\n\t/** Execute query and return an iterator over result rows */\n\titer<R = RET>(params?: ValuesParam<P>): Iterator<R> & Iterable<R>\n\n\t/** Execute query and return a generator that yields result rows */\n\trows<R = RET>(params?: ValuesParam<P>): Generator<R>\n\n\t/** Execute query and return first result row or undefined */\n\tget<R = RET>(params?: ValuesParam<P>): R | undefined\n\n\t/** Execute query and return statement result info */\n\trun(params?: ValuesParam<P>): StatementResultingChanges\n\n\t/** Get SQL with parameters expanded */\n\texpandedSQL(params?: ValuesParam<P>): string\n\n\t/** Get original SQL source */\n\tsourceSQL: (params?: ValuesParam<P>) => string\n\n\t/** Chain another SQL template literal */\n\tsql(\n\t\tstrings: TemplateStringsArray,\n\t\t...params: SqlTemplateValues<P>\n\t): XStatementSync<P, RET>\n}\n\nfunction looksLikeJSON(value: unknown): value is string {\n\tif (typeof value !== \"string\") {\n\t\treturn false\n\t}\n\tconst data = value.trim()\n\treturn (\n\t\t// Only objects and arrays\n\t\t(data.startsWith(\"{\") && data.endsWith(\"}\")) ||\n\t\t(data.startsWith(\"[\") && data.endsWith(\"]\"))\n\t)\n}\n\n/**\n * Helper function to parse JSON columns in result rows\n */\nexport function parseJsonColumns(row: DataRow): DataRow {\n\tconst result = { ...row }\n\n\t// Handle every field in the row that's a string and try to parse it\n\tfor (const [key, value] of Object.entries(result)) {\n\t\tif (looksLikeJSON(value)) {\n\t\t\ttry {\n\t\t\t\tresult[key] = JSON.parse(value)\n\t\t\t} catch {\n\t\t\t\t// Keep original value if parsing fails\n\t\t\t}\n\t\t}\n\t}\n\treturn result\n}\ntype CreateXStatementSyncProps<P extends DataRow> = {\n\tbuild: (params: P) => {\n\t\tstmt: StatementSync\n\t\tnamedParams: Record<string, SupportedValueType>\n\t\thasJsonColumns: boolean\n\t}\n\tprepare: (sql: string) => StatementSync\n\tsql: Sql<P>\n}\n\n/**\n * Creates a type-safe prepared statement\n */\n// Update the factory function\nexport function createXStatementSync<P extends DataRow, RET = unknown>(\n\tprops: CreateXStatementSyncProps<P>\n): XStatementSync<P, RET> {\n\treturn {\n\t\tall<R = RET>(params: ValuesParam<P> = {} as P) {\n\t\t\ttry {\n\t\t\t\tconst { stmt, namedParams, hasJsonColumns } = props.build(params as P)\n\t\t\t\tconst results = stmt.all(namedParams)\n\t\t\t\tif (!results || !results.length) {\n\t\t\t\t\t// No results case\n\t\t\t\t\treturn (Array.isArray(results) ? [] : undefined) as R\n\t\t\t\t}\n\n\t\t\t\tif (!hasJsonColumns) {\n\t\t\t\t\treturn results as R\n\t\t\t\t}\n\n\t\t\t\tif (Array.isArray(results)) {\n\t\t\t\t\t// Array results case\n\t\t\t\t\treturn results.map(row => parseJsonColumns(row as DataRow)) as R\n\t\t\t\t}\n\n\t\t\t\tif (typeof results === \"object\") {\n\t\t\t\t\t// Single object result case\n\t\t\t\t\treturn parseJsonColumns(results as DataRow) as R\n\t\t\t\t}\n\n\t\t\t\t// Primitive value case\n\t\t\t\treturn results as R\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Query execution failed\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\tget<R = RET>(params: ValuesParam<P> = {} as P) {\n\t\t\ttry {\n\t\t\t\tconst { stmt, namedParams, hasJsonColumns } = props.build(params as P)\n\t\t\t\tconst row = stmt.get(namedParams)\n\n\t\t\t\tif (!row) {\n\t\t\t\t\treturn undefined\n\t\t\t\t}\n\n\t\t\t\tif (!hasJsonColumns) {\n\t\t\t\t\treturn row as R\n\t\t\t\t}\n\n\t\t\t\treturn parseJsonColumns(row as DataRow) as R\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Query execution failed\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\trun(params: ValuesParam<P> = {} as P) {\n\t\t\ttry {\n\t\t\t\tconst { stmt, namedParams } = props.build(params as P)\n\t\t\t\treturn stmt.run(namedParams)\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_MUTATE\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Mutation failed\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\titer<R = RET>(params: ValuesParam<P> = {} as P): Iterable<R> & Iterator<R> {\n\t\t\ttry {\n\t\t\t\tconst { stmt, namedParams, hasJsonColumns } = props.build(params as P)\n\t\t\t\t// @ts-expect-error - @types/node is behind\n\t\t\t\tconst baseIterator = stmt.iterate(namedParams)\n\n\t\t\t\treturn {\n\t\t\t\t\t// Iterator protocol\n\t\t\t\t\tnext(): IteratorResult<R> {\n\t\t\t\t\t\tconst result = baseIterator.next()\n\t\t\t\t\t\tif (result.done) {\n\t\t\t\t\t\t\treturn { done: true, value: undefined }\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tdone: false,\n\t\t\t\t\t\t\tvalue: hasJsonColumns\n\t\t\t\t\t\t\t\t? (parseJsonColumns(result.value as DataRow) as R)\n\t\t\t\t\t\t\t\t: (result.value as R),\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\n\t\t\t\t\t// Iterable protocol\n\t\t\t\t\t[Symbol.iterator]() {\n\t\t\t\t\t\treturn this\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Query execution failed\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\t*rows<R = RET>(params: ValuesParam<P> = {} as P): Generator<R> {\n\t\t\ttry {\n\t\t\t\tconst { stmt, namedParams, hasJsonColumns } = props.build(params as P)\n\t\t\t\t// @ts-expect-error - @types/node is behind\n\t\t\t\tconst iterator = stmt.iterate(namedParams)\n\n\t\t\t\tlet result = iterator.next()\n\t\t\t\twhile (!result.done) {\n\t\t\t\t\tconst value = hasJsonColumns\n\t\t\t\t\t\t? (parseJsonColumns(result.value as DataRow) as R)\n\t\t\t\t\t\t: (result.value as R)\n\t\t\t\t\tyield value\n\t\t\t\t\tresult = iterator.next()\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Query execution failed\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\tsourceSQL(params: ValuesParam<P> = {} as P) {\n\t\t\ttry {\n\t\t\t\tconst { stmt } = props.build(params as P)\n\t\t\t\treturn stmt.sourceSQL\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Failed to get expanded SQL\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\texpandedSQL(params: ValuesParam<P> = {} as P) {\n\t\t\ttry {\n\t\t\t\tconst { stmt } = props.build(params as P)\n\t\t\t\treturn stmt.expandedSQL\n\t\t\t} catch (error) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_QUERY\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Failed to get expanded SQL\",\n\t\t\t\t\terror instanceof Error ? error.message : String(error),\n\t\t\t\t\terror instanceof Error ? error : undefined\n\t\t\t\t)\n\t\t\t}\n\t\t},\n\n\t\tsql(strings: TemplateStringsArray, ...params: SqlTemplateValues<P>) {\n\t\t\tconst newBuilder = new Sql({\n\t\t\t\tstrings,\n\t\t\t\tparamOperators: params,\n\t\t\t\tgeneratedSql: props.sql.sql,\n\t\t\t\tformatterConfig: props.sql.formatterConfig,\n\t\t\t})\n\t\t\treturn createXStatementSync({\n\t\t\t\tbuild: finalParams => {\n\t\t\t\t\tconst {\n\t\t\t\t\t\tsql: sqlString,\n\t\t\t\t\t\tnamedParams,\n\t\t\t\t\t\thasJsonColumns,\n\t\t\t\t\t} = newBuilder.prepare(finalParams)\n\t\t\t\t\tconst stmt = props.prepare(sqlString)\n\t\t\t\t\treturn { stmt, namedParams, hasJsonColumns }\n\t\t\t\t},\n\t\t\t\tprepare: props.prepare,\n\t\t\t\tsql: newBuilder,\n\t\t\t})\n\t\t},\n\t}\n}\n",
      "metadata": {
        "size": 16262,
        "modified": 1737787205221.2942,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "types.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\nimport type { StatementSync } from \"node:sqlite\"\nimport type {\n\tFormatterConfig,\n\tSql,\n\tSqlTemplateValues,\n\tXStatementSync,\n} from \"#sql\"\nimport type { CacheStats, StatementCacheOptions } from \"#cache\"\nimport type { PragmaConfig } from \"#pragmas\"\nimport type { Logger } from \"#logger\"\n\n/**\n * Configuration options for database cleanup operations when closing the connection.\n */\nexport interface CleanupPragmas {\n\t/** Runs PRAGMA optimize to optimize the database */\n\toptimize?: boolean\n\n\t/** Runs PRAGMA shrink_memory to release memory back to the system */\n\tshrinkMemory?: boolean\n\n\t/** WAL checkpoint mode to run before closing */\n\twalCheckpoint?: \"PASSIVE\" | \"FULL\" | \"RESTART\" | \"TRUNCATE\"\n}\n\n/**\n * Configuration options for database initialization.\n */\nexport interface DBOptions {\n\t/** Database file path or \":memory:\" for in-memory database */\n\tlocation?: string | \":memory:\"\n\n\t/** Statement cache configuration - boolean to use defaults or detailed options */\n\tstatementCache?: boolean | StatementCacheOptions\n\n\t/** SQLite PRAGMA settings */\n\tpragma?: PragmaConfig\n\n\t/** Runtime environment affecting default PRAGMA settings */\n\tenvironment?: \"development\" | \"testing\" | \"production\"\n\n\t/** Custom logger implementation */\n\tlogger?: Logger\n\n\t/** SQL formatting configuration */\n\tformat?: FormatterConfig\n}\n\n/**\n * Function type for SQL template literal tag\n */\nexport type SqlFn<P extends DataRow> = (\n\tstrings: TemplateStringsArray,\n\t...params: SqlTemplateValues<P>\n) => Sql<P>\n\nexport interface IDatabase {\n\tprepareStatement(sql: string): StatementSync\n\tsql<P extends DataRow, R = unknown>(\n\t\tstrings: TemplateStringsArray,\n\t\t...params: SqlTemplateValues<P>\n\t): XStatementSync<P, R>\n\texec(sql: string): void\n\tbackup(filename: string): void\n\trestore(filename: string): void\n\tgetCacheStats(): CacheStats | undefined\n\tclearStatementCache(): void\n\tclose(pragmas?: CleanupPragmas): void\n}\n\nexport const COMPARISON_OPERATORS = [\n\t\"=\",\n\t\"!=\",\n\t\">\",\n\t\"<\",\n\t\">=\",\n\t\"<=\",\n\t\"LIKE\",\n\t\"NOT LIKE\",\n\t\"IN\",\n\t\"NOT IN\",\n\t\"IS\",\n\t\"IS NOT\",\n] as const\n\nexport const LOGICAL_OPERATORS = [\"AND\", \"OR\"] as const\n\nexport type ComparisonOperator = (typeof COMPARISON_OPERATORS)[number]\nexport type LogicalOperator = (typeof LOGICAL_OPERATORS)[number]\n\n/**\n * A row of data from a database query, or a row of data to be inserted, or a row of data used for query conditions.\n */\n// biome-ignore lint/suspicious/noExplicitAny: <explanation>\nexport type DataRow = { [key: string]: any }\n",
      "metadata": {
        "size": 2626,
        "modified": 1737773087759.731,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },
    "validate.ts": {
      "content": "// Copyright 2025 Takin Profit. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n/**\n * Represents a validation error with a message and optional path indicating where the error occurred.\n * @property _validation_error - Internal flag to identify validation errors\n * @property message - Human-readable error message\n * @property path - Optional path indicating where the error occurred (e.g. \"user.name\")\n */\nexport type ValidationError = {\n\t_validation_error: true\n\tmessage: string\n\tpath?: string\n}\n\nexport const isValidationErr = (value: unknown): value is ValidationError => {\n\treturn (\n\t\ttypeof value === \"object\" && value !== null && \"_validation_error\" in value\n\t)\n}\n\nexport const isValidationErrs = (value: unknown): value is ValidationError[] =>\n\tArray.isArray(value) && value.length > 0 && value.every(isValidationErr)\n\nexport const validationErr = ({\n\tmsg: message,\n\tpath,\n}: {\n\tmsg: string\n\tpath?: string\n}): ValidationError => ({\n\t_validation_error: true,\n\tmessage,\n\tpath,\n})\n",
      "metadata": {
        "size": 1066,
        "modified": 1737759244047.8503,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "values.ts": {
      "content": "import type { InsertOptions } from \"#context.js\"\nimport { NodeSqliteError, SqlitePrimaryResultCode } from \"#errors\"\nimport type { DataRow } from \"#types\"\n\ntype BuildSqlResult = {\n\tcolumns: string[]\n\tplaceholders: string[]\n\tisMulti?: boolean\n\titemCount?: number\n}\n\nfunction buildSqlComponents<P extends DataRow>(\n\toptions: InsertOptions<P>,\n\tparams: P\n): BuildSqlResult {\n\t// First check if params is Array/Set for default multi-row behavior\n\tif ((Array.isArray(params) || params instanceof Set) && options === \"*\") {\n\t\tconst items = Array.from(params)\n\t\tif (items.length === 0) {\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\"Empty data set\",\n\t\t\t\t\"Cannot insert empty array or set\",\n\t\t\t\tundefined\n\t\t\t)\n\t\t}\n\n\t\tconst firstItem = items[0]\n\t\tconst columns = Object.keys(firstItem)\n\t\treturn {\n\t\t\tcolumns,\n\t\t\tplaceholders: columns.map(k => `$${k}`),\n\t\t\tisMulti: true,\n\t\t\titemCount: items.length,\n\t\t}\n\t}\n\n\tif (options === \"*\") {\n\t\tconst columns = Object.keys(params)\n\t\treturn {\n\t\t\tcolumns,\n\t\t\tplaceholders: columns.map(k => `$${k}`),\n\t\t}\n\t}\n\n\tif (Array.isArray(options) && options[0] === \"*\" && options.length === 2) {\n\t\tconst [, config] = options\n\n\t\tif (!config || typeof config !== \"object\") {\n\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\"Invalid configuration\",\n\t\t\t\t\"Second element must be a configuration object\",\n\t\t\t\tundefined\n\t\t\t)\n\t\t}\n\n\t\t// Legacy forEach case\n\t\tif (\"forEach\" in config) {\n\t\t\tif (!Array.isArray(params) && !(params instanceof Set)) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Invalid parameters\",\n\t\t\t\t\t\"Expected array or Set when using forEach\",\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tconst items = Array.from(params)\n\t\t\tif (items.length === 0) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Empty data set\",\n\t\t\t\t\t\"Cannot insert empty array or set\",\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tconst firstItem = items[0]\n\t\t\tconst columns = Object.keys(firstItem)\n\t\t\tconst jsonColumns = new Set(\n\t\t\t\t\"jsonColumns\" in config ? config.jsonColumns : []\n\t\t\t)\n\n\t\t\treturn {\n\t\t\t\tcolumns,\n\t\t\t\tplaceholders: columns.map(col =>\n\t\t\t\t\tjsonColumns.has(col) ? `jsonb($${col})` : `$${col}`\n\t\t\t\t),\n\t\t\t\tisMulti: true,\n\t\t\t\titemCount: items.length,\n\t\t\t}\n\t\t}\n\n\t\t// Handle jsonColumns case\n\t\tif (\"jsonColumns\" in config) {\n\t\t\tconst jsonColumns = new Set(config.jsonColumns)\n\t\t\tconst columns = Object.keys(params)\n\t\t\tconst placeholders = columns.map(col =>\n\t\t\t\tjsonColumns.has(col) ? `jsonb($${col})` : `$${col}`\n\t\t\t)\n\t\t\treturn { columns, placeholders }\n\t\t}\n\n\t\tthrow new NodeSqliteError(\n\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\"Invalid configuration\",\n\t\t\t\"Configuration must include either forEach or jsonColumns\",\n\t\t\tundefined\n\t\t)\n\t}\n\n\tif (Array.isArray(options)) {\n\t\tconst columns: string[] = []\n\t\tconst placeholders: string[] = []\n\n\t\tfor (const op of options) {\n\t\t\tif (typeof op !== \"string\") {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Invalid parameter format\",\n\t\t\t\t\t`Parameter must be a string but got ${typeof op}`,\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tconst match = op.match(/^\\$([^->]+)(->json)?$/)\n\t\t\tif (!match) {\n\t\t\t\tthrow new NodeSqliteError(\n\t\t\t\t\t\"ERR_SQLITE_PARAM\",\n\t\t\t\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\t\t\t\"Invalid parameter format\",\n\t\t\t\t\t`Parameter \"${op}\" must be in format $column or $column->json`,\n\t\t\t\t\tundefined\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tconst column = match[1]\n\t\t\tcolumns.push(column)\n\t\t\tif (op.endsWith(\"->json\")) {\n\t\t\t\tplaceholders.push(`jsonb($${column})`)\n\t\t\t} else {\n\t\t\t\tplaceholders.push(`$${column}`)\n\t\t\t}\n\t\t}\n\n\t\treturn { columns, placeholders }\n\t}\n\n\tthrow new NodeSqliteError(\n\t\t\"ERR_SQLITE_PARAM\",\n\t\tSqlitePrimaryResultCode.SQLITE_ERROR,\n\t\t\"Invalid format\",\n\t\t\"Must be '*', an array of parameters, or a configuration tuple\",\n\t\tundefined\n\t)\n}\n\nexport function buildValuesStatement<P extends DataRow>(\n\tvalues: InsertOptions<P>,\n\tparams: P\n): string {\n\tconst result = buildSqlComponents(values, params)\n\n\tif (result.isMulti && result.itemCount) {\n\t\tconst placeholderRow = `(${result.placeholders.join(\", \")})`\n\n\t\t// For single item, don't add newlines\n\t\tif (result.itemCount === 1) {\n\t\t\treturn `(${result.columns.join(\", \")}) VALUES ${placeholderRow}`\n\t\t}\n\n\t\tconst allRows = Array(result.itemCount).fill(placeholderRow).join(\",\\n    \")\n\t\treturn `(${result.columns.join(\", \")}) VALUES\\n    ${allRows}`\n\t}\n\n\treturn `(${result.columns.join(\", \")}) VALUES (${result.placeholders.join(\", \")})`\n}\n\nexport function buildSetStatement<P extends DataRow>(\n\tset: InsertOptions<P>,\n\tparams: P\n): string {\n\tconst { columns, placeholders } = buildSqlComponents(set, params)\n\tconst setPairs = columns.map((col, i) => `${col} = ${placeholders[i]}`)\n\n\treturn `SET ${setPairs.join(\", \")}`\n}\n",
      "metadata": {
        "size": 4887,
        "modified": 1737781553170.0955,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    },

    "where.ts": {
      "content": "import {\n\tCOMPARISON_OPERATORS,\n\tLOGICAL_OPERATORS,\n\ttype ComparisonOperator,\n\ttype DataRow,\n\ttype LogicalOperator,\n} from \"#types\"\nimport { validationErr, type ValidationError } from \"#validate.js\"\n\n// fields of boolean type should be comparable to other boolean fields, and number fields\n// fields of number type should be comparable to other number fields, and boolean fields\n// string fields should be comparable to other string fields, and boolean fields\n// object fields, arrays, sets, and anything that is not a primitive type should be comparable to other object fields, and arrays and non primitive types\n// more that 5 elements are allowed in the tuple, there is no limit\n\n// Single condition type\ntype SingleWhereCondition<P extends DataRow> =\n\t| `${keyof P & string} ${ComparisonOperator} $${keyof P & string}`\n\t| `${keyof P & string} IS NULL`\n\t| `${keyof P & string} IS NOT NULL`\n\n// Recursive type to enforce alternating condition/operator pattern\ntype ExtendedWhereCondition<P extends DataRow> =\n\t| [SingleWhereCondition<P>, LogicalOperator, SingleWhereCondition<P>]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\t| [\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t\t\tLogicalOperator,\n\t\t\tSingleWhereCondition<P>,\n\t  ]\n\n/**\n * Represents a WHERE clause condition for SQL queries with strongly-typed column references and parameter bindings.\n * Supports single conditions and compound conditions with logical operators (AND/OR).\n * @example\n * // Single condition\n * const where: WhereClause<User> = \"age > $minAge\"\n *\n * // Compound condition\n * const where: WhereClause<User> = [\"age > $minAge\", \"AND\", \"isActive = $active\"]\n */\nexport type WhereClause<P extends DataRow> =\n\t| SingleWhereCondition<P>\n\t| ExtendedWhereCondition<P>\n\nexport function validateWhereClause<P extends DataRow>(\n\twhere: WhereClause<P>\n): ValidationError[] {\n\tconst errors: ValidationError[] = []\n\n\tif (typeof where === \"string\") {\n\t\treturn validateSingleCondition(where)\n\t}\n\n\tif (!Array.isArray(where)) {\n\t\treturn [validationErr({ msg: \"Where clause must be a string or array\" })]\n\t}\n\n\t// Check for minimum length and odd number of elements\n\tif (where.length < 3 || where.length % 2 === 0) {\n\t\treturn [\n\t\t\tvalidationErr({\n\t\t\t\tmsg: \"Where array must have odd number of elements with minimum length 3\",\n\t\t\t}),\n\t\t]\n\t}\n\n\t// Validate conditions and operators alternate correctly\n\tfor (let i = 0; i < where.length; i++) {\n\t\tif (i % 2 === 0) {\n\t\t\t// Should be condition\n\t\t\tconst conditionErrors = validateSingleCondition(where[i])\n\t\t\terrors.push(...conditionErrors)\n\t\t} else if (!LOGICAL_OPERATORS.includes(where[i] as LogicalOperator)) {\n\t\t\terrors.push(\n\t\t\t\tvalidationErr({\n\t\t\t\t\tmsg: `Invalid logical operator at position ${i}`,\n\t\t\t\t\tpath: `[${i}]`,\n\t\t\t\t})\n\t\t\t)\n\t\t}\n\t}\n\n\treturn errors\n}\n\n// In validateSingleCondition\nfunction validateSingleCondition<P extends DataRow>(\n\tcondition: string\n): ValidationError[] {\n\tconst pattern = new RegExp(\n\t\t`^[\\\\w]+\\\\s+(${COMPARISON_OPERATORS.join(\"|\")})\\\\s+\\\\$[\\\\w->json]+$|^[\\\\w]+\\\\s+IS(\\\\s+NOT)?\\\\s+NULL$`\n\t)\n\n\tif (!pattern.test(condition)) {\n\t\treturn [\n\t\t\tvalidationErr({\n\t\t\t\tmsg: `Invalid condition format: ${condition}`,\n\t\t\t\tpath: condition,\n\t\t\t}),\n\t\t]\n\t}\n\n\treturn []\n}\n\nexport function buildWhereStatement(where: WhereClause<DataRow>): string {\n\tif (typeof where === \"string\") {\n\t\tif (where.includes(\"->json\")) {\n\t\t\tconst [field, op, param] = where.trim().split(/\\s+/)\n\t\t\tconst value = param.split(\"->\")[0]\n\t\t\treturn `WHERE ${field} ${op} jsonb(${value})`\n\t\t}\n\t\treturn `WHERE ${where}`\n\t}\n\n\tconst conditions = where\n\t\t.map((part, i) => {\n\t\t\tif (i % 2 === 0 && part.includes(\"->json\")) {\n\t\t\t\tconst [field, op, param] = part.trim().split(/\\s+/)\n\t\t\t\tconst value = param.split(\"->\")[0]\n\t\t\t\treturn `${field} ${op} jsonb(${value})`\n\t\t\t}\n\t\t\treturn i % 2 === 0 ? part : ` ${part} `\n\t\t})\n\t\t.join(\"\")\n\n\treturn `WHERE ${conditions}`\n}\n",
      "metadata": {
        "size": 6635,
        "modified": 1737759303878.7764,
        "extension": ".ts",
        "mimeType": "application/typescript",
        "language": "typescript",
        "encoding": "utf8"
      }
    }
  }
}
